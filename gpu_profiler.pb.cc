// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: gpu_profiler.proto

#include "gpu_profiler.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/descriptor.h>
#include <google/protobuf/generated_message_reflection.h>
#include <google/protobuf/reflection_ops.h>
#include <google/protobuf/wire_format.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>

PROTOBUF_PRAGMA_INIT_SEG

namespace _pb = ::PROTOBUF_NAMESPACE_ID;
namespace _pbi = _pb::internal;

namespace bbts {
PROTOBUF_CONSTEXPR kernel_run_stats_t::kernel_run_stats_t(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.kernel_run_idx_)*/uint64_t{0u}
  , /*decltype(_impl_.start_)*/uint64_t{0u}
  , /*decltype(_impl_.end_)*/uint64_t{0u}
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct kernel_run_stats_tDefaultTypeInternal {
  PROTOBUF_CONSTEXPR kernel_run_stats_tDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~kernel_run_stats_tDefaultTypeInternal() {}
  union {
    kernel_run_stats_t _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 kernel_run_stats_tDefaultTypeInternal _kernel_run_stats_t_default_instance_;
PROTOBUF_CONSTEXPR gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.num_bytes_)*/uint64_t{0u}
  , /*decltype(_impl_.tensor_)*/0
  , /*decltype(_impl_.src_dev_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_tDefaultTypeInternal {
  PROTOBUF_CONSTEXPR gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_tDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_tDefaultTypeInternal() {}
  union {
    gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_tDefaultTypeInternal _gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t_default_instance_;
PROTOBUF_CONSTEXPR gpu_to_gpu_stat_t::gpu_to_gpu_stat_t(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.tensors_)*/{}
  , /*decltype(_impl_.start_)*/uint64_t{0u}
  , /*decltype(_impl_.end_)*/uint64_t{0u}
  , /*decltype(_impl_.source_dev_)*/0
  , /*decltype(_impl_.dst_dev_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct gpu_to_gpu_stat_tDefaultTypeInternal {
  PROTOBUF_CONSTEXPR gpu_to_gpu_stat_tDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~gpu_to_gpu_stat_tDefaultTypeInternal() {}
  union {
    gpu_to_gpu_stat_t _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 gpu_to_gpu_stat_tDefaultTypeInternal _gpu_to_gpu_stat_t_default_instance_;
PROTOBUF_CONSTEXPR cpu_to_gpu_stat_t::cpu_to_gpu_stat_t(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.tensors_)*/{}
  , /*decltype(_impl_._tensors_cached_byte_size_)*/{0}
  , /*decltype(_impl_.start_)*/uint64_t{0u}
  , /*decltype(_impl_.end_)*/uint64_t{0u}
  , /*decltype(_impl_.num_bytes_)*/uint64_t{0u}
  , /*decltype(_impl_.dst_dev_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct cpu_to_gpu_stat_tDefaultTypeInternal {
  PROTOBUF_CONSTEXPR cpu_to_gpu_stat_tDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~cpu_to_gpu_stat_tDefaultTypeInternal() {}
  union {
    cpu_to_gpu_stat_t _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 cpu_to_gpu_stat_tDefaultTypeInternal _cpu_to_gpu_stat_t_default_instance_;
PROTOBUF_CONSTEXPR tensor_freed_stat_t::tensor_freed_stat_t(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.start_)*/uint64_t{0u}
  , /*decltype(_impl_.tensor_)*/0
  , /*decltype(_impl_.dst_dev_)*/0
  , /*decltype(_impl_.num_bytes_)*/uint64_t{0u}
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct tensor_freed_stat_tDefaultTypeInternal {
  PROTOBUF_CONSTEXPR tensor_freed_stat_tDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~tensor_freed_stat_tDefaultTypeInternal() {}
  union {
    tensor_freed_stat_t _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 tensor_freed_stat_tDefaultTypeInternal _tensor_freed_stat_t_default_instance_;
PROTOBUF_CONSTEXPR tensor_evicted_stat_t::tensor_evicted_stat_t(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.start_)*/uint64_t{0u}
  , /*decltype(_impl_.end_)*/uint64_t{0u}
  , /*decltype(_impl_.tensor_)*/0
  , /*decltype(_impl_.dst_dev_)*/0
  , /*decltype(_impl_.num_bytes_)*/uint64_t{0u}
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct tensor_evicted_stat_tDefaultTypeInternal {
  PROTOBUF_CONSTEXPR tensor_evicted_stat_tDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~tensor_evicted_stat_tDefaultTypeInternal() {}
  union {
    tensor_evicted_stat_t _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 tensor_evicted_stat_tDefaultTypeInternal _tensor_evicted_stat_t_default_instance_;
PROTOBUF_CONSTEXPR scheduled_kernel_stat_t_gpu_transfer_stat_t::scheduled_kernel_stat_t_gpu_transfer_stat_t(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.src_dev_)*/0
  , /*decltype(_impl_.tid_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct scheduled_kernel_stat_t_gpu_transfer_stat_tDefaultTypeInternal {
  PROTOBUF_CONSTEXPR scheduled_kernel_stat_t_gpu_transfer_stat_tDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~scheduled_kernel_stat_t_gpu_transfer_stat_tDefaultTypeInternal() {}
  union {
    scheduled_kernel_stat_t_gpu_transfer_stat_t _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 scheduled_kernel_stat_t_gpu_transfer_stat_tDefaultTypeInternal _scheduled_kernel_stat_t_gpu_transfer_stat_t_default_instance_;
PROTOBUF_CONSTEXPR scheduled_kernel_stat_t::scheduled_kernel_stat_t(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.input_)*/{}
  , /*decltype(_impl_._input_cached_byte_size_)*/{0}
  , /*decltype(_impl_.input_sizes_)*/{}
  , /*decltype(_impl_._input_sizes_cached_byte_size_)*/{0}
  , /*decltype(_impl_.output_)*/{}
  , /*decltype(_impl_._output_cached_byte_size_)*/{0}
  , /*decltype(_impl_.output_sizes_)*/{}
  , /*decltype(_impl_._output_sizes_cached_byte_size_)*/{0}
  , /*decltype(_impl_.cpu_transfers_)*/{}
  , /*decltype(_impl_._cpu_transfers_cached_byte_size_)*/{0}
  , /*decltype(_impl_.gpu_transfers_)*/{}
  , /*decltype(_impl_.ud_name_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.impl_name_)*/{&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{}}
  , /*decltype(_impl_.kernel_run_id_)*/uint64_t{0u}
  , /*decltype(_impl_.command_id_)*/uint64_t{0u}
  , /*decltype(_impl_.start_)*/uint64_t{0u}
  , /*decltype(_impl_.dev_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct scheduled_kernel_stat_tDefaultTypeInternal {
  PROTOBUF_CONSTEXPR scheduled_kernel_stat_tDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~scheduled_kernel_stat_tDefaultTypeInternal() {}
  union {
    scheduled_kernel_stat_t _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 scheduled_kernel_stat_tDefaultTypeInternal _scheduled_kernel_stat_t_default_instance_;
PROTOBUF_CONSTEXPR gc_request_free_stat_t::gc_request_free_stat_t(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.num_bytes_)*/uint64_t{0u}
  , /*decltype(_impl_.tid_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct gc_request_free_stat_tDefaultTypeInternal {
  PROTOBUF_CONSTEXPR gc_request_free_stat_tDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~gc_request_free_stat_tDefaultTypeInternal() {}
  union {
    gc_request_free_stat_t _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 gc_request_free_stat_tDefaultTypeInternal _gc_request_free_stat_t_default_instance_;
PROTOBUF_CONSTEXPR gc_request_evict_stat_t::gc_request_evict_stat_t(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.num_bytes_)*/uint64_t{0u}
  , /*decltype(_impl_.tid_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct gc_request_evict_stat_tDefaultTypeInternal {
  PROTOBUF_CONSTEXPR gc_request_evict_stat_tDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~gc_request_evict_stat_tDefaultTypeInternal() {}
  union {
    gc_request_evict_stat_t _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 gc_request_evict_stat_tDefaultTypeInternal _gc_request_evict_stat_t_default_instance_;
PROTOBUF_CONSTEXPR gc_request_stat_t::gc_request_stat_t(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.to_free_)*/{}
  , /*decltype(_impl_.to_evict_)*/{}
  , /*decltype(_impl_.kernel_run_id_)*/uint64_t{0u}
  , /*decltype(_impl_.free_memory_used_)*/uint64_t{0u}
  , /*decltype(_impl_.dev_)*/0
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct gc_request_stat_tDefaultTypeInternal {
  PROTOBUF_CONSTEXPR gc_request_stat_tDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~gc_request_stat_tDefaultTypeInternal() {}
  union {
    gc_request_stat_t _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 gc_request_stat_tDefaultTypeInternal _gc_request_stat_t_default_instance_;
PROTOBUF_CONSTEXPR gpu_device_log_t::gpu_device_log_t(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.kernels_stats_)*/{}
  , /*decltype(_impl_.gpu2gpu_transfer_stats_)*/{}
  , /*decltype(_impl_.cpu2gpu_transfer_stats_)*/{}
  , /*decltype(_impl_.free_tensor_stats_)*/{}
  , /*decltype(_impl_.evicted_tensor_stats_)*/{}
  , /*decltype(_impl_.kernels_scheduled_)*/{}
  , /*decltype(_impl_.gc_scheduled_)*/{}
  , /*decltype(_impl_.num_devices_)*/0u
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct gpu_device_log_tDefaultTypeInternal {
  PROTOBUF_CONSTEXPR gpu_device_log_tDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~gpu_device_log_tDefaultTypeInternal() {}
  union {
    gpu_device_log_t _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 gpu_device_log_tDefaultTypeInternal _gpu_device_log_t_default_instance_;
PROTOBUF_CONSTEXPR gpu_profiler_log_t::gpu_profiler_log_t(
    ::_pbi::ConstantInitialized): _impl_{
    /*decltype(_impl_.device_logs_)*/{}
  , /*decltype(_impl_._cached_size_)*/{}} {}
struct gpu_profiler_log_tDefaultTypeInternal {
  PROTOBUF_CONSTEXPR gpu_profiler_log_tDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~gpu_profiler_log_tDefaultTypeInternal() {}
  union {
    gpu_profiler_log_t _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 gpu_profiler_log_tDefaultTypeInternal _gpu_profiler_log_t_default_instance_;
}  // namespace bbts
static ::_pb::Metadata file_level_metadata_gpu_5fprofiler_2eproto[13];
static constexpr ::_pb::EnumDescriptor const** file_level_enum_descriptors_gpu_5fprofiler_2eproto = nullptr;
static constexpr ::_pb::ServiceDescriptor const** file_level_service_descriptors_gpu_5fprofiler_2eproto = nullptr;

const uint32_t TableStruct_gpu_5fprofiler_2eproto::offsets[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::bbts::kernel_run_stats_t, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _split_
  ~0u,  // no sizeof(Split)
  PROTOBUF_FIELD_OFFSET(::bbts::kernel_run_stats_t, _impl_.kernel_run_idx_),
  PROTOBUF_FIELD_OFFSET(::bbts::kernel_run_stats_t, _impl_.start_),
  PROTOBUF_FIELD_OFFSET(::bbts::kernel_run_stats_t, _impl_.end_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _split_
  ~0u,  // no sizeof(Split)
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t, _impl_.tensor_),
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t, _impl_.num_bytes_),
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t, _impl_.src_dev_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_to_gpu_stat_t, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _split_
  ~0u,  // no sizeof(Split)
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_to_gpu_stat_t, _impl_.start_),
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_to_gpu_stat_t, _impl_.end_),
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_to_gpu_stat_t, _impl_.tensors_),
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_to_gpu_stat_t, _impl_.source_dev_),
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_to_gpu_stat_t, _impl_.dst_dev_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::bbts::cpu_to_gpu_stat_t, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _split_
  ~0u,  // no sizeof(Split)
  PROTOBUF_FIELD_OFFSET(::bbts::cpu_to_gpu_stat_t, _impl_.start_),
  PROTOBUF_FIELD_OFFSET(::bbts::cpu_to_gpu_stat_t, _impl_.end_),
  PROTOBUF_FIELD_OFFSET(::bbts::cpu_to_gpu_stat_t, _impl_.tensors_),
  PROTOBUF_FIELD_OFFSET(::bbts::cpu_to_gpu_stat_t, _impl_.dst_dev_),
  PROTOBUF_FIELD_OFFSET(::bbts::cpu_to_gpu_stat_t, _impl_.num_bytes_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::bbts::tensor_freed_stat_t, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _split_
  ~0u,  // no sizeof(Split)
  PROTOBUF_FIELD_OFFSET(::bbts::tensor_freed_stat_t, _impl_.start_),
  PROTOBUF_FIELD_OFFSET(::bbts::tensor_freed_stat_t, _impl_.tensor_),
  PROTOBUF_FIELD_OFFSET(::bbts::tensor_freed_stat_t, _impl_.dst_dev_),
  PROTOBUF_FIELD_OFFSET(::bbts::tensor_freed_stat_t, _impl_.num_bytes_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::bbts::tensor_evicted_stat_t, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _split_
  ~0u,  // no sizeof(Split)
  PROTOBUF_FIELD_OFFSET(::bbts::tensor_evicted_stat_t, _impl_.start_),
  PROTOBUF_FIELD_OFFSET(::bbts::tensor_evicted_stat_t, _impl_.end_),
  PROTOBUF_FIELD_OFFSET(::bbts::tensor_evicted_stat_t, _impl_.tensor_),
  PROTOBUF_FIELD_OFFSET(::bbts::tensor_evicted_stat_t, _impl_.dst_dev_),
  PROTOBUF_FIELD_OFFSET(::bbts::tensor_evicted_stat_t, _impl_.num_bytes_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::bbts::scheduled_kernel_stat_t_gpu_transfer_stat_t, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _split_
  ~0u,  // no sizeof(Split)
  PROTOBUF_FIELD_OFFSET(::bbts::scheduled_kernel_stat_t_gpu_transfer_stat_t, _impl_.src_dev_),
  PROTOBUF_FIELD_OFFSET(::bbts::scheduled_kernel_stat_t_gpu_transfer_stat_t, _impl_.tid_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::bbts::scheduled_kernel_stat_t, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _split_
  ~0u,  // no sizeof(Split)
  PROTOBUF_FIELD_OFFSET(::bbts::scheduled_kernel_stat_t, _impl_.kernel_run_id_),
  PROTOBUF_FIELD_OFFSET(::bbts::scheduled_kernel_stat_t, _impl_.command_id_),
  PROTOBUF_FIELD_OFFSET(::bbts::scheduled_kernel_stat_t, _impl_.ud_name_),
  PROTOBUF_FIELD_OFFSET(::bbts::scheduled_kernel_stat_t, _impl_.impl_name_),
  PROTOBUF_FIELD_OFFSET(::bbts::scheduled_kernel_stat_t, _impl_.start_),
  PROTOBUF_FIELD_OFFSET(::bbts::scheduled_kernel_stat_t, _impl_.dev_),
  PROTOBUF_FIELD_OFFSET(::bbts::scheduled_kernel_stat_t, _impl_.input_),
  PROTOBUF_FIELD_OFFSET(::bbts::scheduled_kernel_stat_t, _impl_.input_sizes_),
  PROTOBUF_FIELD_OFFSET(::bbts::scheduled_kernel_stat_t, _impl_.output_),
  PROTOBUF_FIELD_OFFSET(::bbts::scheduled_kernel_stat_t, _impl_.output_sizes_),
  PROTOBUF_FIELD_OFFSET(::bbts::scheduled_kernel_stat_t, _impl_.cpu_transfers_),
  PROTOBUF_FIELD_OFFSET(::bbts::scheduled_kernel_stat_t, _impl_.gpu_transfers_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::bbts::gc_request_free_stat_t, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _split_
  ~0u,  // no sizeof(Split)
  PROTOBUF_FIELD_OFFSET(::bbts::gc_request_free_stat_t, _impl_.tid_),
  PROTOBUF_FIELD_OFFSET(::bbts::gc_request_free_stat_t, _impl_.num_bytes_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::bbts::gc_request_evict_stat_t, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _split_
  ~0u,  // no sizeof(Split)
  PROTOBUF_FIELD_OFFSET(::bbts::gc_request_evict_stat_t, _impl_.tid_),
  PROTOBUF_FIELD_OFFSET(::bbts::gc_request_evict_stat_t, _impl_.num_bytes_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::bbts::gc_request_stat_t, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _split_
  ~0u,  // no sizeof(Split)
  PROTOBUF_FIELD_OFFSET(::bbts::gc_request_stat_t, _impl_.dev_),
  PROTOBUF_FIELD_OFFSET(::bbts::gc_request_stat_t, _impl_.to_free_),
  PROTOBUF_FIELD_OFFSET(::bbts::gc_request_stat_t, _impl_.to_evict_),
  PROTOBUF_FIELD_OFFSET(::bbts::gc_request_stat_t, _impl_.kernel_run_id_),
  PROTOBUF_FIELD_OFFSET(::bbts::gc_request_stat_t, _impl_.free_memory_used_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_device_log_t, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _split_
  ~0u,  // no sizeof(Split)
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_device_log_t, _impl_.num_devices_),
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_device_log_t, _impl_.kernels_stats_),
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_device_log_t, _impl_.gpu2gpu_transfer_stats_),
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_device_log_t, _impl_.cpu2gpu_transfer_stats_),
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_device_log_t, _impl_.free_tensor_stats_),
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_device_log_t, _impl_.evicted_tensor_stats_),
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_device_log_t, _impl_.kernels_scheduled_),
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_device_log_t, _impl_.gc_scheduled_),
  ~0u,  // no _has_bits_
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_profiler_log_t, _internal_metadata_),
  ~0u,  // no _extensions_
  ~0u,  // no _oneof_case_
  ~0u,  // no _weak_field_map_
  ~0u,  // no _inlined_string_donated_
  ~0u,  // no _split_
  ~0u,  // no sizeof(Split)
  PROTOBUF_FIELD_OFFSET(::bbts::gpu_profiler_log_t, _impl_.device_logs_),
};
static const ::_pbi::MigrationSchema schemas[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) = {
  { 0, -1, -1, sizeof(::bbts::kernel_run_stats_t)},
  { 11, -1, -1, sizeof(::bbts::gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t)},
  { 22, -1, -1, sizeof(::bbts::gpu_to_gpu_stat_t)},
  { 35, -1, -1, sizeof(::bbts::cpu_to_gpu_stat_t)},
  { 48, -1, -1, sizeof(::bbts::tensor_freed_stat_t)},
  { 60, -1, -1, sizeof(::bbts::tensor_evicted_stat_t)},
  { 73, -1, -1, sizeof(::bbts::scheduled_kernel_stat_t_gpu_transfer_stat_t)},
  { 83, -1, -1, sizeof(::bbts::scheduled_kernel_stat_t)},
  { 103, -1, -1, sizeof(::bbts::gc_request_free_stat_t)},
  { 113, -1, -1, sizeof(::bbts::gc_request_evict_stat_t)},
  { 123, -1, -1, sizeof(::bbts::gc_request_stat_t)},
  { 136, -1, -1, sizeof(::bbts::gpu_device_log_t)},
  { 152, -1, -1, sizeof(::bbts::gpu_profiler_log_t)},
};

static const ::_pb::Message* const file_default_instances[] = {
  &::bbts::_kernel_run_stats_t_default_instance_._instance,
  &::bbts::_gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t_default_instance_._instance,
  &::bbts::_gpu_to_gpu_stat_t_default_instance_._instance,
  &::bbts::_cpu_to_gpu_stat_t_default_instance_._instance,
  &::bbts::_tensor_freed_stat_t_default_instance_._instance,
  &::bbts::_tensor_evicted_stat_t_default_instance_._instance,
  &::bbts::_scheduled_kernel_stat_t_gpu_transfer_stat_t_default_instance_._instance,
  &::bbts::_scheduled_kernel_stat_t_default_instance_._instance,
  &::bbts::_gc_request_free_stat_t_default_instance_._instance,
  &::bbts::_gc_request_evict_stat_t_default_instance_._instance,
  &::bbts::_gc_request_stat_t_default_instance_._instance,
  &::bbts::_gpu_device_log_t_default_instance_._instance,
  &::bbts::_gpu_profiler_log_t_default_instance_._instance,
};

const char descriptor_table_protodef_gpu_5fprofiler_2eproto[] PROTOBUF_SECTION_VARIABLE(protodesc_cold) =
  "\n\022gpu_profiler.proto\022\004bbts\"H\n\022kernel_run"
  "_stats_t\022\026\n\016kernel_run_idx\030\001 \001(\004\022\r\n\005star"
  "t\030\002 \001(\004\022\013\n\003end\030\003 \001(\004\"\347\001\n\021gpu_to_gpu_stat"
  "_t\022\r\n\005start\030\001 \001(\004\022\013\n\003end\030\002 \001(\004\022A\n\007tensor"
  "s\030\003 \003(\01320.bbts.gpu_to_gpu_stat_t.gpu_to_"
  "gpu_tensor_stat_t\022\022\n\nsource_dev\030\004 \001(\005\022\017\n"
  "\007dst_dev\030\005 \001(\005\032N\n\030gpu_to_gpu_tensor_stat"
  "_t\022\016\n\006tensor\030\001 \001(\005\022\021\n\tnum_bytes\030\002 \001(\004\022\017\n"
  "\007src_dev\030\003 \001(\005\"d\n\021cpu_to_gpu_stat_t\022\r\n\005s"
  "tart\030\001 \001(\004\022\013\n\003end\030\002 \001(\004\022\017\n\007tensors\030\003 \003(\005"
  "\022\017\n\007dst_dev\030\004 \001(\005\022\021\n\tnum_bytes\030\005 \001(\004\"X\n\023"
  "tensor_freed_stat_t\022\r\n\005start\030\001 \001(\004\022\016\n\006te"
  "nsor\030\002 \001(\005\022\017\n\007dst_dev\030\003 \001(\005\022\021\n\tnum_bytes"
  "\030\004 \001(\004\"g\n\025tensor_evicted_stat_t\022\r\n\005start"
  "\030\001 \001(\004\022\013\n\003end\030\002 \001(\004\022\016\n\006tensor\030\003 \001(\005\022\017\n\007d"
  "st_dev\030\004 \001(\005\022\021\n\tnum_bytes\030\005 \001(\004\"\344\002\n\027sche"
  "duled_kernel_stat_t\022\025\n\rkernel_run_id\030\001 \001"
  "(\004\022\022\n\ncommand_id\030\002 \001(\004\022\017\n\007ud_name\030\003 \001(\t\022"
  "\021\n\timpl_name\030\004 \001(\t\022\r\n\005start\030\005 \001(\004\022\013\n\003dev"
  "\030\006 \001(\005\022\r\n\005input\030\007 \003(\005\022\023\n\013input_sizes\030\010 \003"
  "(\004\022\016\n\006output\030\t \003(\005\022\024\n\014output_sizes\030\n \003(\004"
  "\022\025\n\rcpu_transfers\030\013 \003(\005\022H\n\rgpu_transfers"
  "\030\014 \003(\01321.bbts.scheduled_kernel_stat_t.gp"
  "u_transfer_stat_t\0323\n\023gpu_transfer_stat_t"
  "\022\017\n\007src_dev\030\001 \001(\005\022\013\n\003tid\030\002 \001(\005\"8\n\026gc_req"
  "uest_free_stat_t\022\013\n\003tid\030\001 \001(\005\022\021\n\tnum_byt"
  "es\030\002 \001(\004\"9\n\027gc_request_evict_stat_t\022\013\n\003t"
  "id\030\001 \001(\005\022\021\n\tnum_bytes\030\002 \001(\004\"\261\001\n\021gc_reque"
  "st_stat_t\022\013\n\003dev\030\001 \001(\005\022-\n\007to_free\030\002 \003(\0132"
  "\034.bbts.gc_request_free_stat_t\022/\n\010to_evic"
  "t\030\003 \003(\0132\035.bbts.gc_request_evict_stat_t\022\025"
  "\n\rkernel_run_id\030\004 \001(\004\022\030\n\020free_memory_use"
  "d\030\005 \001(\004\"\244\003\n\020gpu_device_log_t\022\023\n\013num_devi"
  "ces\030\001 \001(\r\022/\n\rkernels_stats\030\002 \003(\0132\030.bbts."
  "kernel_run_stats_t\0227\n\026gpu2gpu_transfer_s"
  "tats\030\003 \003(\0132\027.bbts.gpu_to_gpu_stat_t\0227\n\026c"
  "pu2gpu_transfer_stats\030\004 \003(\0132\027.bbts.cpu_t"
  "o_gpu_stat_t\0224\n\021free_tensor_stats\030\005 \003(\0132"
  "\031.bbts.tensor_freed_stat_t\0229\n\024evicted_te"
  "nsor_stats\030\006 \003(\0132\033.bbts.tensor_evicted_s"
  "tat_t\0228\n\021kernels_scheduled\030\007 \003(\0132\035.bbts."
  "scheduled_kernel_stat_t\022-\n\014gc_scheduled\030"
  "\010 \003(\0132\027.bbts.gc_request_stat_t\"A\n\022gpu_pr"
  "ofiler_log_t\022+\n\013device_logs\030\001 \003(\0132\026.bbts"
  ".gpu_device_log_tb\006proto3"
  ;
static ::_pbi::once_flag descriptor_table_gpu_5fprofiler_2eproto_once;
const ::_pbi::DescriptorTable descriptor_table_gpu_5fprofiler_2eproto = {
    false, false, 1785, descriptor_table_protodef_gpu_5fprofiler_2eproto,
    "gpu_profiler.proto",
    &descriptor_table_gpu_5fprofiler_2eproto_once, nullptr, 0, 13,
    schemas, file_default_instances, TableStruct_gpu_5fprofiler_2eproto::offsets,
    file_level_metadata_gpu_5fprofiler_2eproto, file_level_enum_descriptors_gpu_5fprofiler_2eproto,
    file_level_service_descriptors_gpu_5fprofiler_2eproto,
};
PROTOBUF_ATTRIBUTE_WEAK const ::_pbi::DescriptorTable* descriptor_table_gpu_5fprofiler_2eproto_getter() {
  return &descriptor_table_gpu_5fprofiler_2eproto;
}

// Force running AddDescriptors() at dynamic initialization time.
PROTOBUF_ATTRIBUTE_INIT_PRIORITY2 static ::_pbi::AddDescriptorsRunner dynamic_init_dummy_gpu_5fprofiler_2eproto(&descriptor_table_gpu_5fprofiler_2eproto);
namespace bbts {

// ===================================================================

class kernel_run_stats_t::_Internal {
 public:
};

kernel_run_stats_t::kernel_run_stats_t(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:bbts.kernel_run_stats_t)
}
kernel_run_stats_t::kernel_run_stats_t(const kernel_run_stats_t& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  kernel_run_stats_t* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.kernel_run_idx_){}
    , decltype(_impl_.start_){}
    , decltype(_impl_.end_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.kernel_run_idx_, &from._impl_.kernel_run_idx_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.end_) -
    reinterpret_cast<char*>(&_impl_.kernel_run_idx_)) + sizeof(_impl_.end_));
  // @@protoc_insertion_point(copy_constructor:bbts.kernel_run_stats_t)
}

inline void kernel_run_stats_t::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.kernel_run_idx_){uint64_t{0u}}
    , decltype(_impl_.start_){uint64_t{0u}}
    , decltype(_impl_.end_){uint64_t{0u}}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

kernel_run_stats_t::~kernel_run_stats_t() {
  // @@protoc_insertion_point(destructor:bbts.kernel_run_stats_t)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void kernel_run_stats_t::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void kernel_run_stats_t::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void kernel_run_stats_t::Clear() {
// @@protoc_insertion_point(message_clear_start:bbts.kernel_run_stats_t)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.kernel_run_idx_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.end_) -
      reinterpret_cast<char*>(&_impl_.kernel_run_idx_)) + sizeof(_impl_.end_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* kernel_run_stats_t::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // uint64 kernel_run_idx = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.kernel_run_idx_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint64 start = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          _impl_.start_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint64 end = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          _impl_.end_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* kernel_run_stats_t::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:bbts.kernel_run_stats_t)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // uint64 kernel_run_idx = 1;
  if (this->_internal_kernel_run_idx() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(1, this->_internal_kernel_run_idx(), target);
  }

  // uint64 start = 2;
  if (this->_internal_start() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(2, this->_internal_start(), target);
  }

  // uint64 end = 3;
  if (this->_internal_end() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(3, this->_internal_end(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:bbts.kernel_run_stats_t)
  return target;
}

size_t kernel_run_stats_t::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:bbts.kernel_run_stats_t)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // uint64 kernel_run_idx = 1;
  if (this->_internal_kernel_run_idx() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_kernel_run_idx());
  }

  // uint64 start = 2;
  if (this->_internal_start() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_start());
  }

  // uint64 end = 3;
  if (this->_internal_end() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_end());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData kernel_run_stats_t::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    kernel_run_stats_t::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*kernel_run_stats_t::GetClassData() const { return &_class_data_; }


void kernel_run_stats_t::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<kernel_run_stats_t*>(&to_msg);
  auto& from = static_cast<const kernel_run_stats_t&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:bbts.kernel_run_stats_t)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_kernel_run_idx() != 0) {
    _this->_internal_set_kernel_run_idx(from._internal_kernel_run_idx());
  }
  if (from._internal_start() != 0) {
    _this->_internal_set_start(from._internal_start());
  }
  if (from._internal_end() != 0) {
    _this->_internal_set_end(from._internal_end());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void kernel_run_stats_t::CopyFrom(const kernel_run_stats_t& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:bbts.kernel_run_stats_t)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool kernel_run_stats_t::IsInitialized() const {
  return true;
}

void kernel_run_stats_t::InternalSwap(kernel_run_stats_t* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(kernel_run_stats_t, _impl_.end_)
      + sizeof(kernel_run_stats_t::_impl_.end_)
      - PROTOBUF_FIELD_OFFSET(kernel_run_stats_t, _impl_.kernel_run_idx_)>(
          reinterpret_cast<char*>(&_impl_.kernel_run_idx_),
          reinterpret_cast<char*>(&other->_impl_.kernel_run_idx_));
}

::PROTOBUF_NAMESPACE_ID::Metadata kernel_run_stats_t::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_gpu_5fprofiler_2eproto_getter, &descriptor_table_gpu_5fprofiler_2eproto_once,
      file_level_metadata_gpu_5fprofiler_2eproto[0]);
}

// ===================================================================

class gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::_Internal {
 public:
};

gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:bbts.gpu_to_gpu_stat_t.gpu_to_gpu_tensor_stat_t)
}
gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t(const gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.num_bytes_){}
    , decltype(_impl_.tensor_){}
    , decltype(_impl_.src_dev_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.num_bytes_, &from._impl_.num_bytes_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.src_dev_) -
    reinterpret_cast<char*>(&_impl_.num_bytes_)) + sizeof(_impl_.src_dev_));
  // @@protoc_insertion_point(copy_constructor:bbts.gpu_to_gpu_stat_t.gpu_to_gpu_tensor_stat_t)
}

inline void gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.num_bytes_){uint64_t{0u}}
    , decltype(_impl_.tensor_){0}
    , decltype(_impl_.src_dev_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::~gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t() {
  // @@protoc_insertion_point(destructor:bbts.gpu_to_gpu_stat_t.gpu_to_gpu_tensor_stat_t)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::Clear() {
// @@protoc_insertion_point(message_clear_start:bbts.gpu_to_gpu_stat_t.gpu_to_gpu_tensor_stat_t)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.num_bytes_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.src_dev_) -
      reinterpret_cast<char*>(&_impl_.num_bytes_)) + sizeof(_impl_.src_dev_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // int32 tensor = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.tensor_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint64 num_bytes = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          _impl_.num_bytes_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int32 src_dev = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          _impl_.src_dev_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:bbts.gpu_to_gpu_stat_t.gpu_to_gpu_tensor_stat_t)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // int32 tensor = 1;
  if (this->_internal_tensor() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(1, this->_internal_tensor(), target);
  }

  // uint64 num_bytes = 2;
  if (this->_internal_num_bytes() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(2, this->_internal_num_bytes(), target);
  }

  // int32 src_dev = 3;
  if (this->_internal_src_dev() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(3, this->_internal_src_dev(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:bbts.gpu_to_gpu_stat_t.gpu_to_gpu_tensor_stat_t)
  return target;
}

size_t gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:bbts.gpu_to_gpu_stat_t.gpu_to_gpu_tensor_stat_t)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // uint64 num_bytes = 2;
  if (this->_internal_num_bytes() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_num_bytes());
  }

  // int32 tensor = 1;
  if (this->_internal_tensor() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_tensor());
  }

  // int32 src_dev = 3;
  if (this->_internal_src_dev() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_src_dev());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::GetClassData() const { return &_class_data_; }


void gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t*>(&to_msg);
  auto& from = static_cast<const gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:bbts.gpu_to_gpu_stat_t.gpu_to_gpu_tensor_stat_t)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_num_bytes() != 0) {
    _this->_internal_set_num_bytes(from._internal_num_bytes());
  }
  if (from._internal_tensor() != 0) {
    _this->_internal_set_tensor(from._internal_tensor());
  }
  if (from._internal_src_dev() != 0) {
    _this->_internal_set_src_dev(from._internal_src_dev());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::CopyFrom(const gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:bbts.gpu_to_gpu_stat_t.gpu_to_gpu_tensor_stat_t)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::IsInitialized() const {
  return true;
}

void gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::InternalSwap(gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t, _impl_.src_dev_)
      + sizeof(gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::_impl_.src_dev_)
      - PROTOBUF_FIELD_OFFSET(gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t, _impl_.num_bytes_)>(
          reinterpret_cast<char*>(&_impl_.num_bytes_),
          reinterpret_cast<char*>(&other->_impl_.num_bytes_));
}

::PROTOBUF_NAMESPACE_ID::Metadata gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_gpu_5fprofiler_2eproto_getter, &descriptor_table_gpu_5fprofiler_2eproto_once,
      file_level_metadata_gpu_5fprofiler_2eproto[1]);
}

// ===================================================================

class gpu_to_gpu_stat_t::_Internal {
 public:
};

gpu_to_gpu_stat_t::gpu_to_gpu_stat_t(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:bbts.gpu_to_gpu_stat_t)
}
gpu_to_gpu_stat_t::gpu_to_gpu_stat_t(const gpu_to_gpu_stat_t& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  gpu_to_gpu_stat_t* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.tensors_){from._impl_.tensors_}
    , decltype(_impl_.start_){}
    , decltype(_impl_.end_){}
    , decltype(_impl_.source_dev_){}
    , decltype(_impl_.dst_dev_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.start_, &from._impl_.start_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.dst_dev_) -
    reinterpret_cast<char*>(&_impl_.start_)) + sizeof(_impl_.dst_dev_));
  // @@protoc_insertion_point(copy_constructor:bbts.gpu_to_gpu_stat_t)
}

inline void gpu_to_gpu_stat_t::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.tensors_){arena}
    , decltype(_impl_.start_){uint64_t{0u}}
    , decltype(_impl_.end_){uint64_t{0u}}
    , decltype(_impl_.source_dev_){0}
    , decltype(_impl_.dst_dev_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

gpu_to_gpu_stat_t::~gpu_to_gpu_stat_t() {
  // @@protoc_insertion_point(destructor:bbts.gpu_to_gpu_stat_t)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void gpu_to_gpu_stat_t::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.tensors_.~RepeatedPtrField();
}

void gpu_to_gpu_stat_t::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void gpu_to_gpu_stat_t::Clear() {
// @@protoc_insertion_point(message_clear_start:bbts.gpu_to_gpu_stat_t)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.tensors_.Clear();
  ::memset(&_impl_.start_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.dst_dev_) -
      reinterpret_cast<char*>(&_impl_.start_)) + sizeof(_impl_.dst_dev_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* gpu_to_gpu_stat_t::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // uint64 start = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.start_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint64 end = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          _impl_.end_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated .bbts.gpu_to_gpu_stat_t.gpu_to_gpu_tensor_stat_t tensors = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_tensors(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<26>(ptr));
        } else
          goto handle_unusual;
        continue;
      // int32 source_dev = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 32)) {
          _impl_.source_dev_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int32 dst_dev = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 40)) {
          _impl_.dst_dev_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* gpu_to_gpu_stat_t::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:bbts.gpu_to_gpu_stat_t)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // uint64 start = 1;
  if (this->_internal_start() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(1, this->_internal_start(), target);
  }

  // uint64 end = 2;
  if (this->_internal_end() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(2, this->_internal_end(), target);
  }

  // repeated .bbts.gpu_to_gpu_stat_t.gpu_to_gpu_tensor_stat_t tensors = 3;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_tensors_size()); i < n; i++) {
    const auto& repfield = this->_internal_tensors(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(3, repfield, repfield.GetCachedSize(), target, stream);
  }

  // int32 source_dev = 4;
  if (this->_internal_source_dev() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(4, this->_internal_source_dev(), target);
  }

  // int32 dst_dev = 5;
  if (this->_internal_dst_dev() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(5, this->_internal_dst_dev(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:bbts.gpu_to_gpu_stat_t)
  return target;
}

size_t gpu_to_gpu_stat_t::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:bbts.gpu_to_gpu_stat_t)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .bbts.gpu_to_gpu_stat_t.gpu_to_gpu_tensor_stat_t tensors = 3;
  total_size += 1UL * this->_internal_tensors_size();
  for (const auto& msg : this->_impl_.tensors_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // uint64 start = 1;
  if (this->_internal_start() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_start());
  }

  // uint64 end = 2;
  if (this->_internal_end() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_end());
  }

  // int32 source_dev = 4;
  if (this->_internal_source_dev() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_source_dev());
  }

  // int32 dst_dev = 5;
  if (this->_internal_dst_dev() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_dst_dev());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData gpu_to_gpu_stat_t::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    gpu_to_gpu_stat_t::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*gpu_to_gpu_stat_t::GetClassData() const { return &_class_data_; }


void gpu_to_gpu_stat_t::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<gpu_to_gpu_stat_t*>(&to_msg);
  auto& from = static_cast<const gpu_to_gpu_stat_t&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:bbts.gpu_to_gpu_stat_t)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.tensors_.MergeFrom(from._impl_.tensors_);
  if (from._internal_start() != 0) {
    _this->_internal_set_start(from._internal_start());
  }
  if (from._internal_end() != 0) {
    _this->_internal_set_end(from._internal_end());
  }
  if (from._internal_source_dev() != 0) {
    _this->_internal_set_source_dev(from._internal_source_dev());
  }
  if (from._internal_dst_dev() != 0) {
    _this->_internal_set_dst_dev(from._internal_dst_dev());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void gpu_to_gpu_stat_t::CopyFrom(const gpu_to_gpu_stat_t& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:bbts.gpu_to_gpu_stat_t)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool gpu_to_gpu_stat_t::IsInitialized() const {
  return true;
}

void gpu_to_gpu_stat_t::InternalSwap(gpu_to_gpu_stat_t* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.tensors_.InternalSwap(&other->_impl_.tensors_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(gpu_to_gpu_stat_t, _impl_.dst_dev_)
      + sizeof(gpu_to_gpu_stat_t::_impl_.dst_dev_)
      - PROTOBUF_FIELD_OFFSET(gpu_to_gpu_stat_t, _impl_.start_)>(
          reinterpret_cast<char*>(&_impl_.start_),
          reinterpret_cast<char*>(&other->_impl_.start_));
}

::PROTOBUF_NAMESPACE_ID::Metadata gpu_to_gpu_stat_t::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_gpu_5fprofiler_2eproto_getter, &descriptor_table_gpu_5fprofiler_2eproto_once,
      file_level_metadata_gpu_5fprofiler_2eproto[2]);
}

// ===================================================================

class cpu_to_gpu_stat_t::_Internal {
 public:
};

cpu_to_gpu_stat_t::cpu_to_gpu_stat_t(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:bbts.cpu_to_gpu_stat_t)
}
cpu_to_gpu_stat_t::cpu_to_gpu_stat_t(const cpu_to_gpu_stat_t& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  cpu_to_gpu_stat_t* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.tensors_){from._impl_.tensors_}
    , /*decltype(_impl_._tensors_cached_byte_size_)*/{0}
    , decltype(_impl_.start_){}
    , decltype(_impl_.end_){}
    , decltype(_impl_.num_bytes_){}
    , decltype(_impl_.dst_dev_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.start_, &from._impl_.start_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.dst_dev_) -
    reinterpret_cast<char*>(&_impl_.start_)) + sizeof(_impl_.dst_dev_));
  // @@protoc_insertion_point(copy_constructor:bbts.cpu_to_gpu_stat_t)
}

inline void cpu_to_gpu_stat_t::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.tensors_){arena}
    , /*decltype(_impl_._tensors_cached_byte_size_)*/{0}
    , decltype(_impl_.start_){uint64_t{0u}}
    , decltype(_impl_.end_){uint64_t{0u}}
    , decltype(_impl_.num_bytes_){uint64_t{0u}}
    , decltype(_impl_.dst_dev_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

cpu_to_gpu_stat_t::~cpu_to_gpu_stat_t() {
  // @@protoc_insertion_point(destructor:bbts.cpu_to_gpu_stat_t)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void cpu_to_gpu_stat_t::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.tensors_.~RepeatedField();
}

void cpu_to_gpu_stat_t::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void cpu_to_gpu_stat_t::Clear() {
// @@protoc_insertion_point(message_clear_start:bbts.cpu_to_gpu_stat_t)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.tensors_.Clear();
  ::memset(&_impl_.start_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.dst_dev_) -
      reinterpret_cast<char*>(&_impl_.start_)) + sizeof(_impl_.dst_dev_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* cpu_to_gpu_stat_t::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // uint64 start = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.start_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint64 end = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          _impl_.end_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated int32 tensors = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedInt32Parser(_internal_mutable_tensors(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 24) {
          _internal_add_tensors(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int32 dst_dev = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 32)) {
          _impl_.dst_dev_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint64 num_bytes = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 40)) {
          _impl_.num_bytes_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* cpu_to_gpu_stat_t::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:bbts.cpu_to_gpu_stat_t)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // uint64 start = 1;
  if (this->_internal_start() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(1, this->_internal_start(), target);
  }

  // uint64 end = 2;
  if (this->_internal_end() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(2, this->_internal_end(), target);
  }

  // repeated int32 tensors = 3;
  {
    int byte_size = _impl_._tensors_cached_byte_size_.Get();
    if (byte_size > 0) {
      target = stream->WriteInt32Packed(
          3, _internal_tensors(), byte_size, target);
    }
  }

  // int32 dst_dev = 4;
  if (this->_internal_dst_dev() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(4, this->_internal_dst_dev(), target);
  }

  // uint64 num_bytes = 5;
  if (this->_internal_num_bytes() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(5, this->_internal_num_bytes(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:bbts.cpu_to_gpu_stat_t)
  return target;
}

size_t cpu_to_gpu_stat_t::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:bbts.cpu_to_gpu_stat_t)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated int32 tensors = 3;
  {
    size_t data_size = ::_pbi::WireFormatLite::
      Int32Size(this->_impl_.tensors_);
    if (data_size > 0) {
      total_size += 1 +
        ::_pbi::WireFormatLite::Int32Size(static_cast<int32_t>(data_size));
    }
    int cached_size = ::_pbi::ToCachedSize(data_size);
    _impl_._tensors_cached_byte_size_.Set(cached_size);
    total_size += data_size;
  }

  // uint64 start = 1;
  if (this->_internal_start() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_start());
  }

  // uint64 end = 2;
  if (this->_internal_end() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_end());
  }

  // uint64 num_bytes = 5;
  if (this->_internal_num_bytes() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_num_bytes());
  }

  // int32 dst_dev = 4;
  if (this->_internal_dst_dev() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_dst_dev());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData cpu_to_gpu_stat_t::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    cpu_to_gpu_stat_t::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*cpu_to_gpu_stat_t::GetClassData() const { return &_class_data_; }


void cpu_to_gpu_stat_t::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<cpu_to_gpu_stat_t*>(&to_msg);
  auto& from = static_cast<const cpu_to_gpu_stat_t&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:bbts.cpu_to_gpu_stat_t)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.tensors_.MergeFrom(from._impl_.tensors_);
  if (from._internal_start() != 0) {
    _this->_internal_set_start(from._internal_start());
  }
  if (from._internal_end() != 0) {
    _this->_internal_set_end(from._internal_end());
  }
  if (from._internal_num_bytes() != 0) {
    _this->_internal_set_num_bytes(from._internal_num_bytes());
  }
  if (from._internal_dst_dev() != 0) {
    _this->_internal_set_dst_dev(from._internal_dst_dev());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void cpu_to_gpu_stat_t::CopyFrom(const cpu_to_gpu_stat_t& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:bbts.cpu_to_gpu_stat_t)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool cpu_to_gpu_stat_t::IsInitialized() const {
  return true;
}

void cpu_to_gpu_stat_t::InternalSwap(cpu_to_gpu_stat_t* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.tensors_.InternalSwap(&other->_impl_.tensors_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(cpu_to_gpu_stat_t, _impl_.dst_dev_)
      + sizeof(cpu_to_gpu_stat_t::_impl_.dst_dev_)
      - PROTOBUF_FIELD_OFFSET(cpu_to_gpu_stat_t, _impl_.start_)>(
          reinterpret_cast<char*>(&_impl_.start_),
          reinterpret_cast<char*>(&other->_impl_.start_));
}

::PROTOBUF_NAMESPACE_ID::Metadata cpu_to_gpu_stat_t::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_gpu_5fprofiler_2eproto_getter, &descriptor_table_gpu_5fprofiler_2eproto_once,
      file_level_metadata_gpu_5fprofiler_2eproto[3]);
}

// ===================================================================

class tensor_freed_stat_t::_Internal {
 public:
};

tensor_freed_stat_t::tensor_freed_stat_t(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:bbts.tensor_freed_stat_t)
}
tensor_freed_stat_t::tensor_freed_stat_t(const tensor_freed_stat_t& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  tensor_freed_stat_t* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.start_){}
    , decltype(_impl_.tensor_){}
    , decltype(_impl_.dst_dev_){}
    , decltype(_impl_.num_bytes_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.start_, &from._impl_.start_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.num_bytes_) -
    reinterpret_cast<char*>(&_impl_.start_)) + sizeof(_impl_.num_bytes_));
  // @@protoc_insertion_point(copy_constructor:bbts.tensor_freed_stat_t)
}

inline void tensor_freed_stat_t::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.start_){uint64_t{0u}}
    , decltype(_impl_.tensor_){0}
    , decltype(_impl_.dst_dev_){0}
    , decltype(_impl_.num_bytes_){uint64_t{0u}}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

tensor_freed_stat_t::~tensor_freed_stat_t() {
  // @@protoc_insertion_point(destructor:bbts.tensor_freed_stat_t)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void tensor_freed_stat_t::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void tensor_freed_stat_t::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void tensor_freed_stat_t::Clear() {
// @@protoc_insertion_point(message_clear_start:bbts.tensor_freed_stat_t)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.start_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.num_bytes_) -
      reinterpret_cast<char*>(&_impl_.start_)) + sizeof(_impl_.num_bytes_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* tensor_freed_stat_t::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // uint64 start = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.start_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int32 tensor = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          _impl_.tensor_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int32 dst_dev = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          _impl_.dst_dev_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint64 num_bytes = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 32)) {
          _impl_.num_bytes_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* tensor_freed_stat_t::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:bbts.tensor_freed_stat_t)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // uint64 start = 1;
  if (this->_internal_start() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(1, this->_internal_start(), target);
  }

  // int32 tensor = 2;
  if (this->_internal_tensor() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(2, this->_internal_tensor(), target);
  }

  // int32 dst_dev = 3;
  if (this->_internal_dst_dev() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(3, this->_internal_dst_dev(), target);
  }

  // uint64 num_bytes = 4;
  if (this->_internal_num_bytes() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(4, this->_internal_num_bytes(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:bbts.tensor_freed_stat_t)
  return target;
}

size_t tensor_freed_stat_t::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:bbts.tensor_freed_stat_t)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // uint64 start = 1;
  if (this->_internal_start() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_start());
  }

  // int32 tensor = 2;
  if (this->_internal_tensor() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_tensor());
  }

  // int32 dst_dev = 3;
  if (this->_internal_dst_dev() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_dst_dev());
  }

  // uint64 num_bytes = 4;
  if (this->_internal_num_bytes() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_num_bytes());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData tensor_freed_stat_t::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    tensor_freed_stat_t::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*tensor_freed_stat_t::GetClassData() const { return &_class_data_; }


void tensor_freed_stat_t::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<tensor_freed_stat_t*>(&to_msg);
  auto& from = static_cast<const tensor_freed_stat_t&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:bbts.tensor_freed_stat_t)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_start() != 0) {
    _this->_internal_set_start(from._internal_start());
  }
  if (from._internal_tensor() != 0) {
    _this->_internal_set_tensor(from._internal_tensor());
  }
  if (from._internal_dst_dev() != 0) {
    _this->_internal_set_dst_dev(from._internal_dst_dev());
  }
  if (from._internal_num_bytes() != 0) {
    _this->_internal_set_num_bytes(from._internal_num_bytes());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void tensor_freed_stat_t::CopyFrom(const tensor_freed_stat_t& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:bbts.tensor_freed_stat_t)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool tensor_freed_stat_t::IsInitialized() const {
  return true;
}

void tensor_freed_stat_t::InternalSwap(tensor_freed_stat_t* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(tensor_freed_stat_t, _impl_.num_bytes_)
      + sizeof(tensor_freed_stat_t::_impl_.num_bytes_)
      - PROTOBUF_FIELD_OFFSET(tensor_freed_stat_t, _impl_.start_)>(
          reinterpret_cast<char*>(&_impl_.start_),
          reinterpret_cast<char*>(&other->_impl_.start_));
}

::PROTOBUF_NAMESPACE_ID::Metadata tensor_freed_stat_t::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_gpu_5fprofiler_2eproto_getter, &descriptor_table_gpu_5fprofiler_2eproto_once,
      file_level_metadata_gpu_5fprofiler_2eproto[4]);
}

// ===================================================================

class tensor_evicted_stat_t::_Internal {
 public:
};

tensor_evicted_stat_t::tensor_evicted_stat_t(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:bbts.tensor_evicted_stat_t)
}
tensor_evicted_stat_t::tensor_evicted_stat_t(const tensor_evicted_stat_t& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  tensor_evicted_stat_t* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.start_){}
    , decltype(_impl_.end_){}
    , decltype(_impl_.tensor_){}
    , decltype(_impl_.dst_dev_){}
    , decltype(_impl_.num_bytes_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.start_, &from._impl_.start_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.num_bytes_) -
    reinterpret_cast<char*>(&_impl_.start_)) + sizeof(_impl_.num_bytes_));
  // @@protoc_insertion_point(copy_constructor:bbts.tensor_evicted_stat_t)
}

inline void tensor_evicted_stat_t::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.start_){uint64_t{0u}}
    , decltype(_impl_.end_){uint64_t{0u}}
    , decltype(_impl_.tensor_){0}
    , decltype(_impl_.dst_dev_){0}
    , decltype(_impl_.num_bytes_){uint64_t{0u}}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

tensor_evicted_stat_t::~tensor_evicted_stat_t() {
  // @@protoc_insertion_point(destructor:bbts.tensor_evicted_stat_t)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void tensor_evicted_stat_t::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void tensor_evicted_stat_t::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void tensor_evicted_stat_t::Clear() {
// @@protoc_insertion_point(message_clear_start:bbts.tensor_evicted_stat_t)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.start_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.num_bytes_) -
      reinterpret_cast<char*>(&_impl_.start_)) + sizeof(_impl_.num_bytes_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* tensor_evicted_stat_t::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // uint64 start = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.start_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint64 end = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          _impl_.end_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int32 tensor = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 24)) {
          _impl_.tensor_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int32 dst_dev = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 32)) {
          _impl_.dst_dev_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint64 num_bytes = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 40)) {
          _impl_.num_bytes_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* tensor_evicted_stat_t::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:bbts.tensor_evicted_stat_t)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // uint64 start = 1;
  if (this->_internal_start() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(1, this->_internal_start(), target);
  }

  // uint64 end = 2;
  if (this->_internal_end() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(2, this->_internal_end(), target);
  }

  // int32 tensor = 3;
  if (this->_internal_tensor() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(3, this->_internal_tensor(), target);
  }

  // int32 dst_dev = 4;
  if (this->_internal_dst_dev() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(4, this->_internal_dst_dev(), target);
  }

  // uint64 num_bytes = 5;
  if (this->_internal_num_bytes() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(5, this->_internal_num_bytes(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:bbts.tensor_evicted_stat_t)
  return target;
}

size_t tensor_evicted_stat_t::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:bbts.tensor_evicted_stat_t)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // uint64 start = 1;
  if (this->_internal_start() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_start());
  }

  // uint64 end = 2;
  if (this->_internal_end() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_end());
  }

  // int32 tensor = 3;
  if (this->_internal_tensor() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_tensor());
  }

  // int32 dst_dev = 4;
  if (this->_internal_dst_dev() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_dst_dev());
  }

  // uint64 num_bytes = 5;
  if (this->_internal_num_bytes() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_num_bytes());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData tensor_evicted_stat_t::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    tensor_evicted_stat_t::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*tensor_evicted_stat_t::GetClassData() const { return &_class_data_; }


void tensor_evicted_stat_t::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<tensor_evicted_stat_t*>(&to_msg);
  auto& from = static_cast<const tensor_evicted_stat_t&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:bbts.tensor_evicted_stat_t)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_start() != 0) {
    _this->_internal_set_start(from._internal_start());
  }
  if (from._internal_end() != 0) {
    _this->_internal_set_end(from._internal_end());
  }
  if (from._internal_tensor() != 0) {
    _this->_internal_set_tensor(from._internal_tensor());
  }
  if (from._internal_dst_dev() != 0) {
    _this->_internal_set_dst_dev(from._internal_dst_dev());
  }
  if (from._internal_num_bytes() != 0) {
    _this->_internal_set_num_bytes(from._internal_num_bytes());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void tensor_evicted_stat_t::CopyFrom(const tensor_evicted_stat_t& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:bbts.tensor_evicted_stat_t)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool tensor_evicted_stat_t::IsInitialized() const {
  return true;
}

void tensor_evicted_stat_t::InternalSwap(tensor_evicted_stat_t* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(tensor_evicted_stat_t, _impl_.num_bytes_)
      + sizeof(tensor_evicted_stat_t::_impl_.num_bytes_)
      - PROTOBUF_FIELD_OFFSET(tensor_evicted_stat_t, _impl_.start_)>(
          reinterpret_cast<char*>(&_impl_.start_),
          reinterpret_cast<char*>(&other->_impl_.start_));
}

::PROTOBUF_NAMESPACE_ID::Metadata tensor_evicted_stat_t::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_gpu_5fprofiler_2eproto_getter, &descriptor_table_gpu_5fprofiler_2eproto_once,
      file_level_metadata_gpu_5fprofiler_2eproto[5]);
}

// ===================================================================

class scheduled_kernel_stat_t_gpu_transfer_stat_t::_Internal {
 public:
};

scheduled_kernel_stat_t_gpu_transfer_stat_t::scheduled_kernel_stat_t_gpu_transfer_stat_t(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:bbts.scheduled_kernel_stat_t.gpu_transfer_stat_t)
}
scheduled_kernel_stat_t_gpu_transfer_stat_t::scheduled_kernel_stat_t_gpu_transfer_stat_t(const scheduled_kernel_stat_t_gpu_transfer_stat_t& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  scheduled_kernel_stat_t_gpu_transfer_stat_t* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.src_dev_){}
    , decltype(_impl_.tid_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.src_dev_, &from._impl_.src_dev_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.tid_) -
    reinterpret_cast<char*>(&_impl_.src_dev_)) + sizeof(_impl_.tid_));
  // @@protoc_insertion_point(copy_constructor:bbts.scheduled_kernel_stat_t.gpu_transfer_stat_t)
}

inline void scheduled_kernel_stat_t_gpu_transfer_stat_t::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.src_dev_){0}
    , decltype(_impl_.tid_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

scheduled_kernel_stat_t_gpu_transfer_stat_t::~scheduled_kernel_stat_t_gpu_transfer_stat_t() {
  // @@protoc_insertion_point(destructor:bbts.scheduled_kernel_stat_t.gpu_transfer_stat_t)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void scheduled_kernel_stat_t_gpu_transfer_stat_t::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void scheduled_kernel_stat_t_gpu_transfer_stat_t::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void scheduled_kernel_stat_t_gpu_transfer_stat_t::Clear() {
// @@protoc_insertion_point(message_clear_start:bbts.scheduled_kernel_stat_t.gpu_transfer_stat_t)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.src_dev_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.tid_) -
      reinterpret_cast<char*>(&_impl_.src_dev_)) + sizeof(_impl_.tid_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* scheduled_kernel_stat_t_gpu_transfer_stat_t::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // int32 src_dev = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.src_dev_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int32 tid = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          _impl_.tid_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* scheduled_kernel_stat_t_gpu_transfer_stat_t::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:bbts.scheduled_kernel_stat_t.gpu_transfer_stat_t)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // int32 src_dev = 1;
  if (this->_internal_src_dev() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(1, this->_internal_src_dev(), target);
  }

  // int32 tid = 2;
  if (this->_internal_tid() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(2, this->_internal_tid(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:bbts.scheduled_kernel_stat_t.gpu_transfer_stat_t)
  return target;
}

size_t scheduled_kernel_stat_t_gpu_transfer_stat_t::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:bbts.scheduled_kernel_stat_t.gpu_transfer_stat_t)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // int32 src_dev = 1;
  if (this->_internal_src_dev() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_src_dev());
  }

  // int32 tid = 2;
  if (this->_internal_tid() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_tid());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData scheduled_kernel_stat_t_gpu_transfer_stat_t::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    scheduled_kernel_stat_t_gpu_transfer_stat_t::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*scheduled_kernel_stat_t_gpu_transfer_stat_t::GetClassData() const { return &_class_data_; }


void scheduled_kernel_stat_t_gpu_transfer_stat_t::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<scheduled_kernel_stat_t_gpu_transfer_stat_t*>(&to_msg);
  auto& from = static_cast<const scheduled_kernel_stat_t_gpu_transfer_stat_t&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:bbts.scheduled_kernel_stat_t.gpu_transfer_stat_t)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_src_dev() != 0) {
    _this->_internal_set_src_dev(from._internal_src_dev());
  }
  if (from._internal_tid() != 0) {
    _this->_internal_set_tid(from._internal_tid());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void scheduled_kernel_stat_t_gpu_transfer_stat_t::CopyFrom(const scheduled_kernel_stat_t_gpu_transfer_stat_t& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:bbts.scheduled_kernel_stat_t.gpu_transfer_stat_t)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool scheduled_kernel_stat_t_gpu_transfer_stat_t::IsInitialized() const {
  return true;
}

void scheduled_kernel_stat_t_gpu_transfer_stat_t::InternalSwap(scheduled_kernel_stat_t_gpu_transfer_stat_t* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(scheduled_kernel_stat_t_gpu_transfer_stat_t, _impl_.tid_)
      + sizeof(scheduled_kernel_stat_t_gpu_transfer_stat_t::_impl_.tid_)
      - PROTOBUF_FIELD_OFFSET(scheduled_kernel_stat_t_gpu_transfer_stat_t, _impl_.src_dev_)>(
          reinterpret_cast<char*>(&_impl_.src_dev_),
          reinterpret_cast<char*>(&other->_impl_.src_dev_));
}

::PROTOBUF_NAMESPACE_ID::Metadata scheduled_kernel_stat_t_gpu_transfer_stat_t::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_gpu_5fprofiler_2eproto_getter, &descriptor_table_gpu_5fprofiler_2eproto_once,
      file_level_metadata_gpu_5fprofiler_2eproto[6]);
}

// ===================================================================

class scheduled_kernel_stat_t::_Internal {
 public:
};

scheduled_kernel_stat_t::scheduled_kernel_stat_t(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:bbts.scheduled_kernel_stat_t)
}
scheduled_kernel_stat_t::scheduled_kernel_stat_t(const scheduled_kernel_stat_t& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  scheduled_kernel_stat_t* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.input_){from._impl_.input_}
    , /*decltype(_impl_._input_cached_byte_size_)*/{0}
    , decltype(_impl_.input_sizes_){from._impl_.input_sizes_}
    , /*decltype(_impl_._input_sizes_cached_byte_size_)*/{0}
    , decltype(_impl_.output_){from._impl_.output_}
    , /*decltype(_impl_._output_cached_byte_size_)*/{0}
    , decltype(_impl_.output_sizes_){from._impl_.output_sizes_}
    , /*decltype(_impl_._output_sizes_cached_byte_size_)*/{0}
    , decltype(_impl_.cpu_transfers_){from._impl_.cpu_transfers_}
    , /*decltype(_impl_._cpu_transfers_cached_byte_size_)*/{0}
    , decltype(_impl_.gpu_transfers_){from._impl_.gpu_transfers_}
    , decltype(_impl_.ud_name_){}
    , decltype(_impl_.impl_name_){}
    , decltype(_impl_.kernel_run_id_){}
    , decltype(_impl_.command_id_){}
    , decltype(_impl_.start_){}
    , decltype(_impl_.dev_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _impl_.ud_name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.ud_name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_ud_name().empty()) {
    _this->_impl_.ud_name_.Set(from._internal_ud_name(), 
      _this->GetArenaForAllocation());
  }
  _impl_.impl_name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.impl_name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (!from._internal_impl_name().empty()) {
    _this->_impl_.impl_name_.Set(from._internal_impl_name(), 
      _this->GetArenaForAllocation());
  }
  ::memcpy(&_impl_.kernel_run_id_, &from._impl_.kernel_run_id_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.dev_) -
    reinterpret_cast<char*>(&_impl_.kernel_run_id_)) + sizeof(_impl_.dev_));
  // @@protoc_insertion_point(copy_constructor:bbts.scheduled_kernel_stat_t)
}

inline void scheduled_kernel_stat_t::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.input_){arena}
    , /*decltype(_impl_._input_cached_byte_size_)*/{0}
    , decltype(_impl_.input_sizes_){arena}
    , /*decltype(_impl_._input_sizes_cached_byte_size_)*/{0}
    , decltype(_impl_.output_){arena}
    , /*decltype(_impl_._output_cached_byte_size_)*/{0}
    , decltype(_impl_.output_sizes_){arena}
    , /*decltype(_impl_._output_sizes_cached_byte_size_)*/{0}
    , decltype(_impl_.cpu_transfers_){arena}
    , /*decltype(_impl_._cpu_transfers_cached_byte_size_)*/{0}
    , decltype(_impl_.gpu_transfers_){arena}
    , decltype(_impl_.ud_name_){}
    , decltype(_impl_.impl_name_){}
    , decltype(_impl_.kernel_run_id_){uint64_t{0u}}
    , decltype(_impl_.command_id_){uint64_t{0u}}
    , decltype(_impl_.start_){uint64_t{0u}}
    , decltype(_impl_.dev_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
  _impl_.ud_name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.ud_name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  _impl_.impl_name_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    _impl_.impl_name_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
}

scheduled_kernel_stat_t::~scheduled_kernel_stat_t() {
  // @@protoc_insertion_point(destructor:bbts.scheduled_kernel_stat_t)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void scheduled_kernel_stat_t::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.input_.~RepeatedField();
  _impl_.input_sizes_.~RepeatedField();
  _impl_.output_.~RepeatedField();
  _impl_.output_sizes_.~RepeatedField();
  _impl_.cpu_transfers_.~RepeatedField();
  _impl_.gpu_transfers_.~RepeatedPtrField();
  _impl_.ud_name_.Destroy();
  _impl_.impl_name_.Destroy();
}

void scheduled_kernel_stat_t::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void scheduled_kernel_stat_t::Clear() {
// @@protoc_insertion_point(message_clear_start:bbts.scheduled_kernel_stat_t)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.input_.Clear();
  _impl_.input_sizes_.Clear();
  _impl_.output_.Clear();
  _impl_.output_sizes_.Clear();
  _impl_.cpu_transfers_.Clear();
  _impl_.gpu_transfers_.Clear();
  _impl_.ud_name_.ClearToEmpty();
  _impl_.impl_name_.ClearToEmpty();
  ::memset(&_impl_.kernel_run_id_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.dev_) -
      reinterpret_cast<char*>(&_impl_.kernel_run_id_)) + sizeof(_impl_.dev_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* scheduled_kernel_stat_t::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // uint64 kernel_run_id = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.kernel_run_id_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint64 command_id = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          _impl_.command_id_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // string ud_name = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          auto str = _internal_mutable_ud_name();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
          CHK_(::_pbi::VerifyUTF8(str, "bbts.scheduled_kernel_stat_t.ud_name"));
        } else
          goto handle_unusual;
        continue;
      // string impl_name = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 34)) {
          auto str = _internal_mutable_impl_name();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
          CHK_(::_pbi::VerifyUTF8(str, "bbts.scheduled_kernel_stat_t.impl_name"));
        } else
          goto handle_unusual;
        continue;
      // uint64 start = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 40)) {
          _impl_.start_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // int32 dev = 6;
      case 6:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 48)) {
          _impl_.dev_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated int32 input = 7;
      case 7:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 58)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedInt32Parser(_internal_mutable_input(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 56) {
          _internal_add_input(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated uint64 input_sizes = 8;
      case 8:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 66)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedUInt64Parser(_internal_mutable_input_sizes(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 64) {
          _internal_add_input_sizes(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated int32 output = 9;
      case 9:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 74)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedInt32Parser(_internal_mutable_output(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 72) {
          _internal_add_output(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated uint64 output_sizes = 10;
      case 10:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 82)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedUInt64Parser(_internal_mutable_output_sizes(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 80) {
          _internal_add_output_sizes(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated int32 cpu_transfers = 11;
      case 11:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 90)) {
          ptr = ::PROTOBUF_NAMESPACE_ID::internal::PackedInt32Parser(_internal_mutable_cpu_transfers(), ptr, ctx);
          CHK_(ptr);
        } else if (static_cast<uint8_t>(tag) == 88) {
          _internal_add_cpu_transfers(::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr));
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated .bbts.scheduled_kernel_stat_t.gpu_transfer_stat_t gpu_transfers = 12;
      case 12:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 98)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_gpu_transfers(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<98>(ptr));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* scheduled_kernel_stat_t::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:bbts.scheduled_kernel_stat_t)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // uint64 kernel_run_id = 1;
  if (this->_internal_kernel_run_id() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(1, this->_internal_kernel_run_id(), target);
  }

  // uint64 command_id = 2;
  if (this->_internal_command_id() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(2, this->_internal_command_id(), target);
  }

  // string ud_name = 3;
  if (!this->_internal_ud_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_ud_name().data(), static_cast<int>(this->_internal_ud_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "bbts.scheduled_kernel_stat_t.ud_name");
    target = stream->WriteStringMaybeAliased(
        3, this->_internal_ud_name(), target);
  }

  // string impl_name = 4;
  if (!this->_internal_impl_name().empty()) {
    ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::VerifyUtf8String(
      this->_internal_impl_name().data(), static_cast<int>(this->_internal_impl_name().length()),
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::SERIALIZE,
      "bbts.scheduled_kernel_stat_t.impl_name");
    target = stream->WriteStringMaybeAliased(
        4, this->_internal_impl_name(), target);
  }

  // uint64 start = 5;
  if (this->_internal_start() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(5, this->_internal_start(), target);
  }

  // int32 dev = 6;
  if (this->_internal_dev() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(6, this->_internal_dev(), target);
  }

  // repeated int32 input = 7;
  {
    int byte_size = _impl_._input_cached_byte_size_.Get();
    if (byte_size > 0) {
      target = stream->WriteInt32Packed(
          7, _internal_input(), byte_size, target);
    }
  }

  // repeated uint64 input_sizes = 8;
  {
    int byte_size = _impl_._input_sizes_cached_byte_size_.Get();
    if (byte_size > 0) {
      target = stream->WriteUInt64Packed(
          8, _internal_input_sizes(), byte_size, target);
    }
  }

  // repeated int32 output = 9;
  {
    int byte_size = _impl_._output_cached_byte_size_.Get();
    if (byte_size > 0) {
      target = stream->WriteInt32Packed(
          9, _internal_output(), byte_size, target);
    }
  }

  // repeated uint64 output_sizes = 10;
  {
    int byte_size = _impl_._output_sizes_cached_byte_size_.Get();
    if (byte_size > 0) {
      target = stream->WriteUInt64Packed(
          10, _internal_output_sizes(), byte_size, target);
    }
  }

  // repeated int32 cpu_transfers = 11;
  {
    int byte_size = _impl_._cpu_transfers_cached_byte_size_.Get();
    if (byte_size > 0) {
      target = stream->WriteInt32Packed(
          11, _internal_cpu_transfers(), byte_size, target);
    }
  }

  // repeated .bbts.scheduled_kernel_stat_t.gpu_transfer_stat_t gpu_transfers = 12;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_gpu_transfers_size()); i < n; i++) {
    const auto& repfield = this->_internal_gpu_transfers(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(12, repfield, repfield.GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:bbts.scheduled_kernel_stat_t)
  return target;
}

size_t scheduled_kernel_stat_t::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:bbts.scheduled_kernel_stat_t)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated int32 input = 7;
  {
    size_t data_size = ::_pbi::WireFormatLite::
      Int32Size(this->_impl_.input_);
    if (data_size > 0) {
      total_size += 1 +
        ::_pbi::WireFormatLite::Int32Size(static_cast<int32_t>(data_size));
    }
    int cached_size = ::_pbi::ToCachedSize(data_size);
    _impl_._input_cached_byte_size_.Set(cached_size);
    total_size += data_size;
  }

  // repeated uint64 input_sizes = 8;
  {
    size_t data_size = ::_pbi::WireFormatLite::
      UInt64Size(this->_impl_.input_sizes_);
    if (data_size > 0) {
      total_size += 1 +
        ::_pbi::WireFormatLite::Int32Size(static_cast<int32_t>(data_size));
    }
    int cached_size = ::_pbi::ToCachedSize(data_size);
    _impl_._input_sizes_cached_byte_size_.Set(cached_size);
    total_size += data_size;
  }

  // repeated int32 output = 9;
  {
    size_t data_size = ::_pbi::WireFormatLite::
      Int32Size(this->_impl_.output_);
    if (data_size > 0) {
      total_size += 1 +
        ::_pbi::WireFormatLite::Int32Size(static_cast<int32_t>(data_size));
    }
    int cached_size = ::_pbi::ToCachedSize(data_size);
    _impl_._output_cached_byte_size_.Set(cached_size);
    total_size += data_size;
  }

  // repeated uint64 output_sizes = 10;
  {
    size_t data_size = ::_pbi::WireFormatLite::
      UInt64Size(this->_impl_.output_sizes_);
    if (data_size > 0) {
      total_size += 1 +
        ::_pbi::WireFormatLite::Int32Size(static_cast<int32_t>(data_size));
    }
    int cached_size = ::_pbi::ToCachedSize(data_size);
    _impl_._output_sizes_cached_byte_size_.Set(cached_size);
    total_size += data_size;
  }

  // repeated int32 cpu_transfers = 11;
  {
    size_t data_size = ::_pbi::WireFormatLite::
      Int32Size(this->_impl_.cpu_transfers_);
    if (data_size > 0) {
      total_size += 1 +
        ::_pbi::WireFormatLite::Int32Size(static_cast<int32_t>(data_size));
    }
    int cached_size = ::_pbi::ToCachedSize(data_size);
    _impl_._cpu_transfers_cached_byte_size_.Set(cached_size);
    total_size += data_size;
  }

  // repeated .bbts.scheduled_kernel_stat_t.gpu_transfer_stat_t gpu_transfers = 12;
  total_size += 1UL * this->_internal_gpu_transfers_size();
  for (const auto& msg : this->_impl_.gpu_transfers_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // string ud_name = 3;
  if (!this->_internal_ud_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_ud_name());
  }

  // string impl_name = 4;
  if (!this->_internal_impl_name().empty()) {
    total_size += 1 +
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::StringSize(
        this->_internal_impl_name());
  }

  // uint64 kernel_run_id = 1;
  if (this->_internal_kernel_run_id() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_kernel_run_id());
  }

  // uint64 command_id = 2;
  if (this->_internal_command_id() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_command_id());
  }

  // uint64 start = 5;
  if (this->_internal_start() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_start());
  }

  // int32 dev = 6;
  if (this->_internal_dev() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_dev());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData scheduled_kernel_stat_t::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    scheduled_kernel_stat_t::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*scheduled_kernel_stat_t::GetClassData() const { return &_class_data_; }


void scheduled_kernel_stat_t::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<scheduled_kernel_stat_t*>(&to_msg);
  auto& from = static_cast<const scheduled_kernel_stat_t&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:bbts.scheduled_kernel_stat_t)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.input_.MergeFrom(from._impl_.input_);
  _this->_impl_.input_sizes_.MergeFrom(from._impl_.input_sizes_);
  _this->_impl_.output_.MergeFrom(from._impl_.output_);
  _this->_impl_.output_sizes_.MergeFrom(from._impl_.output_sizes_);
  _this->_impl_.cpu_transfers_.MergeFrom(from._impl_.cpu_transfers_);
  _this->_impl_.gpu_transfers_.MergeFrom(from._impl_.gpu_transfers_);
  if (!from._internal_ud_name().empty()) {
    _this->_internal_set_ud_name(from._internal_ud_name());
  }
  if (!from._internal_impl_name().empty()) {
    _this->_internal_set_impl_name(from._internal_impl_name());
  }
  if (from._internal_kernel_run_id() != 0) {
    _this->_internal_set_kernel_run_id(from._internal_kernel_run_id());
  }
  if (from._internal_command_id() != 0) {
    _this->_internal_set_command_id(from._internal_command_id());
  }
  if (from._internal_start() != 0) {
    _this->_internal_set_start(from._internal_start());
  }
  if (from._internal_dev() != 0) {
    _this->_internal_set_dev(from._internal_dev());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void scheduled_kernel_stat_t::CopyFrom(const scheduled_kernel_stat_t& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:bbts.scheduled_kernel_stat_t)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool scheduled_kernel_stat_t::IsInitialized() const {
  return true;
}

void scheduled_kernel_stat_t::InternalSwap(scheduled_kernel_stat_t* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.input_.InternalSwap(&other->_impl_.input_);
  _impl_.input_sizes_.InternalSwap(&other->_impl_.input_sizes_);
  _impl_.output_.InternalSwap(&other->_impl_.output_);
  _impl_.output_sizes_.InternalSwap(&other->_impl_.output_sizes_);
  _impl_.cpu_transfers_.InternalSwap(&other->_impl_.cpu_transfers_);
  _impl_.gpu_transfers_.InternalSwap(&other->_impl_.gpu_transfers_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.ud_name_, lhs_arena,
      &other->_impl_.ud_name_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &_impl_.impl_name_, lhs_arena,
      &other->_impl_.impl_name_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(scheduled_kernel_stat_t, _impl_.dev_)
      + sizeof(scheduled_kernel_stat_t::_impl_.dev_)
      - PROTOBUF_FIELD_OFFSET(scheduled_kernel_stat_t, _impl_.kernel_run_id_)>(
          reinterpret_cast<char*>(&_impl_.kernel_run_id_),
          reinterpret_cast<char*>(&other->_impl_.kernel_run_id_));
}

::PROTOBUF_NAMESPACE_ID::Metadata scheduled_kernel_stat_t::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_gpu_5fprofiler_2eproto_getter, &descriptor_table_gpu_5fprofiler_2eproto_once,
      file_level_metadata_gpu_5fprofiler_2eproto[7]);
}

// ===================================================================

class gc_request_free_stat_t::_Internal {
 public:
};

gc_request_free_stat_t::gc_request_free_stat_t(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:bbts.gc_request_free_stat_t)
}
gc_request_free_stat_t::gc_request_free_stat_t(const gc_request_free_stat_t& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  gc_request_free_stat_t* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.num_bytes_){}
    , decltype(_impl_.tid_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.num_bytes_, &from._impl_.num_bytes_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.tid_) -
    reinterpret_cast<char*>(&_impl_.num_bytes_)) + sizeof(_impl_.tid_));
  // @@protoc_insertion_point(copy_constructor:bbts.gc_request_free_stat_t)
}

inline void gc_request_free_stat_t::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.num_bytes_){uint64_t{0u}}
    , decltype(_impl_.tid_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

gc_request_free_stat_t::~gc_request_free_stat_t() {
  // @@protoc_insertion_point(destructor:bbts.gc_request_free_stat_t)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void gc_request_free_stat_t::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void gc_request_free_stat_t::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void gc_request_free_stat_t::Clear() {
// @@protoc_insertion_point(message_clear_start:bbts.gc_request_free_stat_t)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.num_bytes_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.tid_) -
      reinterpret_cast<char*>(&_impl_.num_bytes_)) + sizeof(_impl_.tid_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* gc_request_free_stat_t::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // int32 tid = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.tid_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint64 num_bytes = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          _impl_.num_bytes_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* gc_request_free_stat_t::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:bbts.gc_request_free_stat_t)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // int32 tid = 1;
  if (this->_internal_tid() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(1, this->_internal_tid(), target);
  }

  // uint64 num_bytes = 2;
  if (this->_internal_num_bytes() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(2, this->_internal_num_bytes(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:bbts.gc_request_free_stat_t)
  return target;
}

size_t gc_request_free_stat_t::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:bbts.gc_request_free_stat_t)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // uint64 num_bytes = 2;
  if (this->_internal_num_bytes() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_num_bytes());
  }

  // int32 tid = 1;
  if (this->_internal_tid() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_tid());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData gc_request_free_stat_t::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    gc_request_free_stat_t::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*gc_request_free_stat_t::GetClassData() const { return &_class_data_; }


void gc_request_free_stat_t::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<gc_request_free_stat_t*>(&to_msg);
  auto& from = static_cast<const gc_request_free_stat_t&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:bbts.gc_request_free_stat_t)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_num_bytes() != 0) {
    _this->_internal_set_num_bytes(from._internal_num_bytes());
  }
  if (from._internal_tid() != 0) {
    _this->_internal_set_tid(from._internal_tid());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void gc_request_free_stat_t::CopyFrom(const gc_request_free_stat_t& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:bbts.gc_request_free_stat_t)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool gc_request_free_stat_t::IsInitialized() const {
  return true;
}

void gc_request_free_stat_t::InternalSwap(gc_request_free_stat_t* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(gc_request_free_stat_t, _impl_.tid_)
      + sizeof(gc_request_free_stat_t::_impl_.tid_)
      - PROTOBUF_FIELD_OFFSET(gc_request_free_stat_t, _impl_.num_bytes_)>(
          reinterpret_cast<char*>(&_impl_.num_bytes_),
          reinterpret_cast<char*>(&other->_impl_.num_bytes_));
}

::PROTOBUF_NAMESPACE_ID::Metadata gc_request_free_stat_t::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_gpu_5fprofiler_2eproto_getter, &descriptor_table_gpu_5fprofiler_2eproto_once,
      file_level_metadata_gpu_5fprofiler_2eproto[8]);
}

// ===================================================================

class gc_request_evict_stat_t::_Internal {
 public:
};

gc_request_evict_stat_t::gc_request_evict_stat_t(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:bbts.gc_request_evict_stat_t)
}
gc_request_evict_stat_t::gc_request_evict_stat_t(const gc_request_evict_stat_t& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  gc_request_evict_stat_t* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.num_bytes_){}
    , decltype(_impl_.tid_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.num_bytes_, &from._impl_.num_bytes_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.tid_) -
    reinterpret_cast<char*>(&_impl_.num_bytes_)) + sizeof(_impl_.tid_));
  // @@protoc_insertion_point(copy_constructor:bbts.gc_request_evict_stat_t)
}

inline void gc_request_evict_stat_t::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.num_bytes_){uint64_t{0u}}
    , decltype(_impl_.tid_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

gc_request_evict_stat_t::~gc_request_evict_stat_t() {
  // @@protoc_insertion_point(destructor:bbts.gc_request_evict_stat_t)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void gc_request_evict_stat_t::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
}

void gc_request_evict_stat_t::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void gc_request_evict_stat_t::Clear() {
// @@protoc_insertion_point(message_clear_start:bbts.gc_request_evict_stat_t)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  ::memset(&_impl_.num_bytes_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.tid_) -
      reinterpret_cast<char*>(&_impl_.num_bytes_)) + sizeof(_impl_.tid_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* gc_request_evict_stat_t::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // int32 tid = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.tid_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint64 num_bytes = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 16)) {
          _impl_.num_bytes_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* gc_request_evict_stat_t::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:bbts.gc_request_evict_stat_t)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // int32 tid = 1;
  if (this->_internal_tid() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(1, this->_internal_tid(), target);
  }

  // uint64 num_bytes = 2;
  if (this->_internal_num_bytes() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(2, this->_internal_num_bytes(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:bbts.gc_request_evict_stat_t)
  return target;
}

size_t gc_request_evict_stat_t::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:bbts.gc_request_evict_stat_t)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // uint64 num_bytes = 2;
  if (this->_internal_num_bytes() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_num_bytes());
  }

  // int32 tid = 1;
  if (this->_internal_tid() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_tid());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData gc_request_evict_stat_t::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    gc_request_evict_stat_t::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*gc_request_evict_stat_t::GetClassData() const { return &_class_data_; }


void gc_request_evict_stat_t::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<gc_request_evict_stat_t*>(&to_msg);
  auto& from = static_cast<const gc_request_evict_stat_t&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:bbts.gc_request_evict_stat_t)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  if (from._internal_num_bytes() != 0) {
    _this->_internal_set_num_bytes(from._internal_num_bytes());
  }
  if (from._internal_tid() != 0) {
    _this->_internal_set_tid(from._internal_tid());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void gc_request_evict_stat_t::CopyFrom(const gc_request_evict_stat_t& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:bbts.gc_request_evict_stat_t)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool gc_request_evict_stat_t::IsInitialized() const {
  return true;
}

void gc_request_evict_stat_t::InternalSwap(gc_request_evict_stat_t* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(gc_request_evict_stat_t, _impl_.tid_)
      + sizeof(gc_request_evict_stat_t::_impl_.tid_)
      - PROTOBUF_FIELD_OFFSET(gc_request_evict_stat_t, _impl_.num_bytes_)>(
          reinterpret_cast<char*>(&_impl_.num_bytes_),
          reinterpret_cast<char*>(&other->_impl_.num_bytes_));
}

::PROTOBUF_NAMESPACE_ID::Metadata gc_request_evict_stat_t::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_gpu_5fprofiler_2eproto_getter, &descriptor_table_gpu_5fprofiler_2eproto_once,
      file_level_metadata_gpu_5fprofiler_2eproto[9]);
}

// ===================================================================

class gc_request_stat_t::_Internal {
 public:
};

gc_request_stat_t::gc_request_stat_t(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:bbts.gc_request_stat_t)
}
gc_request_stat_t::gc_request_stat_t(const gc_request_stat_t& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  gc_request_stat_t* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.to_free_){from._impl_.to_free_}
    , decltype(_impl_.to_evict_){from._impl_.to_evict_}
    , decltype(_impl_.kernel_run_id_){}
    , decltype(_impl_.free_memory_used_){}
    , decltype(_impl_.dev_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  ::memcpy(&_impl_.kernel_run_id_, &from._impl_.kernel_run_id_,
    static_cast<size_t>(reinterpret_cast<char*>(&_impl_.dev_) -
    reinterpret_cast<char*>(&_impl_.kernel_run_id_)) + sizeof(_impl_.dev_));
  // @@protoc_insertion_point(copy_constructor:bbts.gc_request_stat_t)
}

inline void gc_request_stat_t::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.to_free_){arena}
    , decltype(_impl_.to_evict_){arena}
    , decltype(_impl_.kernel_run_id_){uint64_t{0u}}
    , decltype(_impl_.free_memory_used_){uint64_t{0u}}
    , decltype(_impl_.dev_){0}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

gc_request_stat_t::~gc_request_stat_t() {
  // @@protoc_insertion_point(destructor:bbts.gc_request_stat_t)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void gc_request_stat_t::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.to_free_.~RepeatedPtrField();
  _impl_.to_evict_.~RepeatedPtrField();
}

void gc_request_stat_t::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void gc_request_stat_t::Clear() {
// @@protoc_insertion_point(message_clear_start:bbts.gc_request_stat_t)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.to_free_.Clear();
  _impl_.to_evict_.Clear();
  ::memset(&_impl_.kernel_run_id_, 0, static_cast<size_t>(
      reinterpret_cast<char*>(&_impl_.dev_) -
      reinterpret_cast<char*>(&_impl_.kernel_run_id_)) + sizeof(_impl_.dev_));
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* gc_request_stat_t::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // int32 dev = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.dev_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated .bbts.gc_request_free_stat_t to_free = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_to_free(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<18>(ptr));
        } else
          goto handle_unusual;
        continue;
      // repeated .bbts.gc_request_evict_stat_t to_evict = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_to_evict(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<26>(ptr));
        } else
          goto handle_unusual;
        continue;
      // uint64 kernel_run_id = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 32)) {
          _impl_.kernel_run_id_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // uint64 free_memory_used = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 40)) {
          _impl_.free_memory_used_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint64(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* gc_request_stat_t::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:bbts.gc_request_stat_t)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // int32 dev = 1;
  if (this->_internal_dev() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteInt32ToArray(1, this->_internal_dev(), target);
  }

  // repeated .bbts.gc_request_free_stat_t to_free = 2;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_to_free_size()); i < n; i++) {
    const auto& repfield = this->_internal_to_free(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(2, repfield, repfield.GetCachedSize(), target, stream);
  }

  // repeated .bbts.gc_request_evict_stat_t to_evict = 3;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_to_evict_size()); i < n; i++) {
    const auto& repfield = this->_internal_to_evict(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(3, repfield, repfield.GetCachedSize(), target, stream);
  }

  // uint64 kernel_run_id = 4;
  if (this->_internal_kernel_run_id() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(4, this->_internal_kernel_run_id(), target);
  }

  // uint64 free_memory_used = 5;
  if (this->_internal_free_memory_used() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt64ToArray(5, this->_internal_free_memory_used(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:bbts.gc_request_stat_t)
  return target;
}

size_t gc_request_stat_t::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:bbts.gc_request_stat_t)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .bbts.gc_request_free_stat_t to_free = 2;
  total_size += 1UL * this->_internal_to_free_size();
  for (const auto& msg : this->_impl_.to_free_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // repeated .bbts.gc_request_evict_stat_t to_evict = 3;
  total_size += 1UL * this->_internal_to_evict_size();
  for (const auto& msg : this->_impl_.to_evict_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // uint64 kernel_run_id = 4;
  if (this->_internal_kernel_run_id() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_kernel_run_id());
  }

  // uint64 free_memory_used = 5;
  if (this->_internal_free_memory_used() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt64SizePlusOne(this->_internal_free_memory_used());
  }

  // int32 dev = 1;
  if (this->_internal_dev() != 0) {
    total_size += ::_pbi::WireFormatLite::Int32SizePlusOne(this->_internal_dev());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData gc_request_stat_t::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    gc_request_stat_t::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*gc_request_stat_t::GetClassData() const { return &_class_data_; }


void gc_request_stat_t::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<gc_request_stat_t*>(&to_msg);
  auto& from = static_cast<const gc_request_stat_t&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:bbts.gc_request_stat_t)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.to_free_.MergeFrom(from._impl_.to_free_);
  _this->_impl_.to_evict_.MergeFrom(from._impl_.to_evict_);
  if (from._internal_kernel_run_id() != 0) {
    _this->_internal_set_kernel_run_id(from._internal_kernel_run_id());
  }
  if (from._internal_free_memory_used() != 0) {
    _this->_internal_set_free_memory_used(from._internal_free_memory_used());
  }
  if (from._internal_dev() != 0) {
    _this->_internal_set_dev(from._internal_dev());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void gc_request_stat_t::CopyFrom(const gc_request_stat_t& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:bbts.gc_request_stat_t)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool gc_request_stat_t::IsInitialized() const {
  return true;
}

void gc_request_stat_t::InternalSwap(gc_request_stat_t* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.to_free_.InternalSwap(&other->_impl_.to_free_);
  _impl_.to_evict_.InternalSwap(&other->_impl_.to_evict_);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(gc_request_stat_t, _impl_.dev_)
      + sizeof(gc_request_stat_t::_impl_.dev_)
      - PROTOBUF_FIELD_OFFSET(gc_request_stat_t, _impl_.kernel_run_id_)>(
          reinterpret_cast<char*>(&_impl_.kernel_run_id_),
          reinterpret_cast<char*>(&other->_impl_.kernel_run_id_));
}

::PROTOBUF_NAMESPACE_ID::Metadata gc_request_stat_t::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_gpu_5fprofiler_2eproto_getter, &descriptor_table_gpu_5fprofiler_2eproto_once,
      file_level_metadata_gpu_5fprofiler_2eproto[10]);
}

// ===================================================================

class gpu_device_log_t::_Internal {
 public:
};

gpu_device_log_t::gpu_device_log_t(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:bbts.gpu_device_log_t)
}
gpu_device_log_t::gpu_device_log_t(const gpu_device_log_t& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  gpu_device_log_t* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.kernels_stats_){from._impl_.kernels_stats_}
    , decltype(_impl_.gpu2gpu_transfer_stats_){from._impl_.gpu2gpu_transfer_stats_}
    , decltype(_impl_.cpu2gpu_transfer_stats_){from._impl_.cpu2gpu_transfer_stats_}
    , decltype(_impl_.free_tensor_stats_){from._impl_.free_tensor_stats_}
    , decltype(_impl_.evicted_tensor_stats_){from._impl_.evicted_tensor_stats_}
    , decltype(_impl_.kernels_scheduled_){from._impl_.kernels_scheduled_}
    , decltype(_impl_.gc_scheduled_){from._impl_.gc_scheduled_}
    , decltype(_impl_.num_devices_){}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  _this->_impl_.num_devices_ = from._impl_.num_devices_;
  // @@protoc_insertion_point(copy_constructor:bbts.gpu_device_log_t)
}

inline void gpu_device_log_t::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.kernels_stats_){arena}
    , decltype(_impl_.gpu2gpu_transfer_stats_){arena}
    , decltype(_impl_.cpu2gpu_transfer_stats_){arena}
    , decltype(_impl_.free_tensor_stats_){arena}
    , decltype(_impl_.evicted_tensor_stats_){arena}
    , decltype(_impl_.kernels_scheduled_){arena}
    , decltype(_impl_.gc_scheduled_){arena}
    , decltype(_impl_.num_devices_){0u}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

gpu_device_log_t::~gpu_device_log_t() {
  // @@protoc_insertion_point(destructor:bbts.gpu_device_log_t)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void gpu_device_log_t::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.kernels_stats_.~RepeatedPtrField();
  _impl_.gpu2gpu_transfer_stats_.~RepeatedPtrField();
  _impl_.cpu2gpu_transfer_stats_.~RepeatedPtrField();
  _impl_.free_tensor_stats_.~RepeatedPtrField();
  _impl_.evicted_tensor_stats_.~RepeatedPtrField();
  _impl_.kernels_scheduled_.~RepeatedPtrField();
  _impl_.gc_scheduled_.~RepeatedPtrField();
}

void gpu_device_log_t::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void gpu_device_log_t::Clear() {
// @@protoc_insertion_point(message_clear_start:bbts.gpu_device_log_t)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.kernels_stats_.Clear();
  _impl_.gpu2gpu_transfer_stats_.Clear();
  _impl_.cpu2gpu_transfer_stats_.Clear();
  _impl_.free_tensor_stats_.Clear();
  _impl_.evicted_tensor_stats_.Clear();
  _impl_.kernels_scheduled_.Clear();
  _impl_.gc_scheduled_.Clear();
  _impl_.num_devices_ = 0u;
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* gpu_device_log_t::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // uint32 num_devices = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 8)) {
          _impl_.num_devices_ = ::PROTOBUF_NAMESPACE_ID::internal::ReadVarint32(&ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // repeated .bbts.kernel_run_stats_t kernels_stats = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_kernels_stats(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<18>(ptr));
        } else
          goto handle_unusual;
        continue;
      // repeated .bbts.gpu_to_gpu_stat_t gpu2gpu_transfer_stats = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 26)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_gpu2gpu_transfer_stats(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<26>(ptr));
        } else
          goto handle_unusual;
        continue;
      // repeated .bbts.cpu_to_gpu_stat_t cpu2gpu_transfer_stats = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 34)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_cpu2gpu_transfer_stats(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<34>(ptr));
        } else
          goto handle_unusual;
        continue;
      // repeated .bbts.tensor_freed_stat_t free_tensor_stats = 5;
      case 5:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 42)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_free_tensor_stats(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<42>(ptr));
        } else
          goto handle_unusual;
        continue;
      // repeated .bbts.tensor_evicted_stat_t evicted_tensor_stats = 6;
      case 6:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 50)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_evicted_tensor_stats(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<50>(ptr));
        } else
          goto handle_unusual;
        continue;
      // repeated .bbts.scheduled_kernel_stat_t kernels_scheduled = 7;
      case 7:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 58)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_kernels_scheduled(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<58>(ptr));
        } else
          goto handle_unusual;
        continue;
      // repeated .bbts.gc_request_stat_t gc_scheduled = 8;
      case 8:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 66)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_gc_scheduled(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<66>(ptr));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* gpu_device_log_t::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:bbts.gpu_device_log_t)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // uint32 num_devices = 1;
  if (this->_internal_num_devices() != 0) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteUInt32ToArray(1, this->_internal_num_devices(), target);
  }

  // repeated .bbts.kernel_run_stats_t kernels_stats = 2;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_kernels_stats_size()); i < n; i++) {
    const auto& repfield = this->_internal_kernels_stats(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(2, repfield, repfield.GetCachedSize(), target, stream);
  }

  // repeated .bbts.gpu_to_gpu_stat_t gpu2gpu_transfer_stats = 3;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_gpu2gpu_transfer_stats_size()); i < n; i++) {
    const auto& repfield = this->_internal_gpu2gpu_transfer_stats(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(3, repfield, repfield.GetCachedSize(), target, stream);
  }

  // repeated .bbts.cpu_to_gpu_stat_t cpu2gpu_transfer_stats = 4;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_cpu2gpu_transfer_stats_size()); i < n; i++) {
    const auto& repfield = this->_internal_cpu2gpu_transfer_stats(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(4, repfield, repfield.GetCachedSize(), target, stream);
  }

  // repeated .bbts.tensor_freed_stat_t free_tensor_stats = 5;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_free_tensor_stats_size()); i < n; i++) {
    const auto& repfield = this->_internal_free_tensor_stats(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(5, repfield, repfield.GetCachedSize(), target, stream);
  }

  // repeated .bbts.tensor_evicted_stat_t evicted_tensor_stats = 6;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_evicted_tensor_stats_size()); i < n; i++) {
    const auto& repfield = this->_internal_evicted_tensor_stats(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(6, repfield, repfield.GetCachedSize(), target, stream);
  }

  // repeated .bbts.scheduled_kernel_stat_t kernels_scheduled = 7;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_kernels_scheduled_size()); i < n; i++) {
    const auto& repfield = this->_internal_kernels_scheduled(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(7, repfield, repfield.GetCachedSize(), target, stream);
  }

  // repeated .bbts.gc_request_stat_t gc_scheduled = 8;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_gc_scheduled_size()); i < n; i++) {
    const auto& repfield = this->_internal_gc_scheduled(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(8, repfield, repfield.GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:bbts.gpu_device_log_t)
  return target;
}

size_t gpu_device_log_t::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:bbts.gpu_device_log_t)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .bbts.kernel_run_stats_t kernels_stats = 2;
  total_size += 1UL * this->_internal_kernels_stats_size();
  for (const auto& msg : this->_impl_.kernels_stats_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // repeated .bbts.gpu_to_gpu_stat_t gpu2gpu_transfer_stats = 3;
  total_size += 1UL * this->_internal_gpu2gpu_transfer_stats_size();
  for (const auto& msg : this->_impl_.gpu2gpu_transfer_stats_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // repeated .bbts.cpu_to_gpu_stat_t cpu2gpu_transfer_stats = 4;
  total_size += 1UL * this->_internal_cpu2gpu_transfer_stats_size();
  for (const auto& msg : this->_impl_.cpu2gpu_transfer_stats_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // repeated .bbts.tensor_freed_stat_t free_tensor_stats = 5;
  total_size += 1UL * this->_internal_free_tensor_stats_size();
  for (const auto& msg : this->_impl_.free_tensor_stats_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // repeated .bbts.tensor_evicted_stat_t evicted_tensor_stats = 6;
  total_size += 1UL * this->_internal_evicted_tensor_stats_size();
  for (const auto& msg : this->_impl_.evicted_tensor_stats_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // repeated .bbts.scheduled_kernel_stat_t kernels_scheduled = 7;
  total_size += 1UL * this->_internal_kernels_scheduled_size();
  for (const auto& msg : this->_impl_.kernels_scheduled_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // repeated .bbts.gc_request_stat_t gc_scheduled = 8;
  total_size += 1UL * this->_internal_gc_scheduled_size();
  for (const auto& msg : this->_impl_.gc_scheduled_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  // uint32 num_devices = 1;
  if (this->_internal_num_devices() != 0) {
    total_size += ::_pbi::WireFormatLite::UInt32SizePlusOne(this->_internal_num_devices());
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData gpu_device_log_t::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    gpu_device_log_t::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*gpu_device_log_t::GetClassData() const { return &_class_data_; }


void gpu_device_log_t::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<gpu_device_log_t*>(&to_msg);
  auto& from = static_cast<const gpu_device_log_t&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:bbts.gpu_device_log_t)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.kernels_stats_.MergeFrom(from._impl_.kernels_stats_);
  _this->_impl_.gpu2gpu_transfer_stats_.MergeFrom(from._impl_.gpu2gpu_transfer_stats_);
  _this->_impl_.cpu2gpu_transfer_stats_.MergeFrom(from._impl_.cpu2gpu_transfer_stats_);
  _this->_impl_.free_tensor_stats_.MergeFrom(from._impl_.free_tensor_stats_);
  _this->_impl_.evicted_tensor_stats_.MergeFrom(from._impl_.evicted_tensor_stats_);
  _this->_impl_.kernels_scheduled_.MergeFrom(from._impl_.kernels_scheduled_);
  _this->_impl_.gc_scheduled_.MergeFrom(from._impl_.gc_scheduled_);
  if (from._internal_num_devices() != 0) {
    _this->_internal_set_num_devices(from._internal_num_devices());
  }
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void gpu_device_log_t::CopyFrom(const gpu_device_log_t& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:bbts.gpu_device_log_t)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool gpu_device_log_t::IsInitialized() const {
  return true;
}

void gpu_device_log_t::InternalSwap(gpu_device_log_t* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.kernels_stats_.InternalSwap(&other->_impl_.kernels_stats_);
  _impl_.gpu2gpu_transfer_stats_.InternalSwap(&other->_impl_.gpu2gpu_transfer_stats_);
  _impl_.cpu2gpu_transfer_stats_.InternalSwap(&other->_impl_.cpu2gpu_transfer_stats_);
  _impl_.free_tensor_stats_.InternalSwap(&other->_impl_.free_tensor_stats_);
  _impl_.evicted_tensor_stats_.InternalSwap(&other->_impl_.evicted_tensor_stats_);
  _impl_.kernels_scheduled_.InternalSwap(&other->_impl_.kernels_scheduled_);
  _impl_.gc_scheduled_.InternalSwap(&other->_impl_.gc_scheduled_);
  swap(_impl_.num_devices_, other->_impl_.num_devices_);
}

::PROTOBUF_NAMESPACE_ID::Metadata gpu_device_log_t::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_gpu_5fprofiler_2eproto_getter, &descriptor_table_gpu_5fprofiler_2eproto_once,
      file_level_metadata_gpu_5fprofiler_2eproto[11]);
}

// ===================================================================

class gpu_profiler_log_t::_Internal {
 public:
};

gpu_profiler_log_t::gpu_profiler_log_t(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::Message(arena, is_message_owned) {
  SharedCtor(arena, is_message_owned);
  // @@protoc_insertion_point(arena_constructor:bbts.gpu_profiler_log_t)
}
gpu_profiler_log_t::gpu_profiler_log_t(const gpu_profiler_log_t& from)
  : ::PROTOBUF_NAMESPACE_ID::Message() {
  gpu_profiler_log_t* const _this = this; (void)_this;
  new (&_impl_) Impl_{
      decltype(_impl_.device_logs_){from._impl_.device_logs_}
    , /*decltype(_impl_._cached_size_)*/{}};

  _internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
  // @@protoc_insertion_point(copy_constructor:bbts.gpu_profiler_log_t)
}

inline void gpu_profiler_log_t::SharedCtor(
    ::_pb::Arena* arena, bool is_message_owned) {
  (void)arena;
  (void)is_message_owned;
  new (&_impl_) Impl_{
      decltype(_impl_.device_logs_){arena}
    , /*decltype(_impl_._cached_size_)*/{}
  };
}

gpu_profiler_log_t::~gpu_profiler_log_t() {
  // @@protoc_insertion_point(destructor:bbts.gpu_profiler_log_t)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void gpu_profiler_log_t::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  _impl_.device_logs_.~RepeatedPtrField();
}

void gpu_profiler_log_t::SetCachedSize(int size) const {
  _impl_._cached_size_.Set(size);
}

void gpu_profiler_log_t::Clear() {
// @@protoc_insertion_point(message_clear_start:bbts.gpu_profiler_log_t)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  _impl_.device_logs_.Clear();
  _internal_metadata_.Clear<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>();
}

const char* gpu_profiler_log_t::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // repeated .bbts.gpu_device_log_t device_logs = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr -= 1;
          do {
            ptr += 1;
            ptr = ctx->ParseMessage(_internal_add_device_logs(), ptr);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<10>(ptr));
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* gpu_profiler_log_t::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:bbts.gpu_profiler_log_t)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // repeated .bbts.gpu_device_log_t device_logs = 1;
  for (unsigned i = 0,
      n = static_cast<unsigned>(this->_internal_device_logs_size()); i < n; i++) {
    const auto& repfield = this->_internal_device_logs(i);
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
        InternalWriteMessage(1, repfield, repfield.GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = ::_pbi::WireFormat::InternalSerializeUnknownFieldsToArray(
        _internal_metadata_.unknown_fields<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(::PROTOBUF_NAMESPACE_ID::UnknownFieldSet::default_instance), target, stream);
  }
  // @@protoc_insertion_point(serialize_to_array_end:bbts.gpu_profiler_log_t)
  return target;
}

size_t gpu_profiler_log_t::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:bbts.gpu_profiler_log_t)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated .bbts.gpu_device_log_t device_logs = 1;
  total_size += 1UL * this->_internal_device_logs_size();
  for (const auto& msg : this->_impl_.device_logs_) {
    total_size +=
      ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(msg);
  }

  return MaybeComputeUnknownFieldsSize(total_size, &_impl_._cached_size_);
}

const ::PROTOBUF_NAMESPACE_ID::Message::ClassData gpu_profiler_log_t::_class_data_ = {
    ::PROTOBUF_NAMESPACE_ID::Message::CopyWithSourceCheck,
    gpu_profiler_log_t::MergeImpl
};
const ::PROTOBUF_NAMESPACE_ID::Message::ClassData*gpu_profiler_log_t::GetClassData() const { return &_class_data_; }


void gpu_profiler_log_t::MergeImpl(::PROTOBUF_NAMESPACE_ID::Message& to_msg, const ::PROTOBUF_NAMESPACE_ID::Message& from_msg) {
  auto* const _this = static_cast<gpu_profiler_log_t*>(&to_msg);
  auto& from = static_cast<const gpu_profiler_log_t&>(from_msg);
  // @@protoc_insertion_point(class_specific_merge_from_start:bbts.gpu_profiler_log_t)
  GOOGLE_DCHECK_NE(&from, _this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  _this->_impl_.device_logs_.MergeFrom(from._impl_.device_logs_);
  _this->_internal_metadata_.MergeFrom<::PROTOBUF_NAMESPACE_ID::UnknownFieldSet>(from._internal_metadata_);
}

void gpu_profiler_log_t::CopyFrom(const gpu_profiler_log_t& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:bbts.gpu_profiler_log_t)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool gpu_profiler_log_t::IsInitialized() const {
  return true;
}

void gpu_profiler_log_t::InternalSwap(gpu_profiler_log_t* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  _impl_.device_logs_.InternalSwap(&other->_impl_.device_logs_);
}

::PROTOBUF_NAMESPACE_ID::Metadata gpu_profiler_log_t::GetMetadata() const {
  return ::_pbi::AssignDescriptors(
      &descriptor_table_gpu_5fprofiler_2eproto_getter, &descriptor_table_gpu_5fprofiler_2eproto_once,
      file_level_metadata_gpu_5fprofiler_2eproto[12]);
}

// @@protoc_insertion_point(namespace_scope)
}  // namespace bbts
PROTOBUF_NAMESPACE_OPEN
template<> PROTOBUF_NOINLINE ::bbts::kernel_run_stats_t*
Arena::CreateMaybeMessage< ::bbts::kernel_run_stats_t >(Arena* arena) {
  return Arena::CreateMessageInternal< ::bbts::kernel_run_stats_t >(arena);
}
template<> PROTOBUF_NOINLINE ::bbts::gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t*
Arena::CreateMaybeMessage< ::bbts::gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t >(Arena* arena) {
  return Arena::CreateMessageInternal< ::bbts::gpu_to_gpu_stat_t_gpu_to_gpu_tensor_stat_t >(arena);
}
template<> PROTOBUF_NOINLINE ::bbts::gpu_to_gpu_stat_t*
Arena::CreateMaybeMessage< ::bbts::gpu_to_gpu_stat_t >(Arena* arena) {
  return Arena::CreateMessageInternal< ::bbts::gpu_to_gpu_stat_t >(arena);
}
template<> PROTOBUF_NOINLINE ::bbts::cpu_to_gpu_stat_t*
Arena::CreateMaybeMessage< ::bbts::cpu_to_gpu_stat_t >(Arena* arena) {
  return Arena::CreateMessageInternal< ::bbts::cpu_to_gpu_stat_t >(arena);
}
template<> PROTOBUF_NOINLINE ::bbts::tensor_freed_stat_t*
Arena::CreateMaybeMessage< ::bbts::tensor_freed_stat_t >(Arena* arena) {
  return Arena::CreateMessageInternal< ::bbts::tensor_freed_stat_t >(arena);
}
template<> PROTOBUF_NOINLINE ::bbts::tensor_evicted_stat_t*
Arena::CreateMaybeMessage< ::bbts::tensor_evicted_stat_t >(Arena* arena) {
  return Arena::CreateMessageInternal< ::bbts::tensor_evicted_stat_t >(arena);
}
template<> PROTOBUF_NOINLINE ::bbts::scheduled_kernel_stat_t_gpu_transfer_stat_t*
Arena::CreateMaybeMessage< ::bbts::scheduled_kernel_stat_t_gpu_transfer_stat_t >(Arena* arena) {
  return Arena::CreateMessageInternal< ::bbts::scheduled_kernel_stat_t_gpu_transfer_stat_t >(arena);
}
template<> PROTOBUF_NOINLINE ::bbts::scheduled_kernel_stat_t*
Arena::CreateMaybeMessage< ::bbts::scheduled_kernel_stat_t >(Arena* arena) {
  return Arena::CreateMessageInternal< ::bbts::scheduled_kernel_stat_t >(arena);
}
template<> PROTOBUF_NOINLINE ::bbts::gc_request_free_stat_t*
Arena::CreateMaybeMessage< ::bbts::gc_request_free_stat_t >(Arena* arena) {
  return Arena::CreateMessageInternal< ::bbts::gc_request_free_stat_t >(arena);
}
template<> PROTOBUF_NOINLINE ::bbts::gc_request_evict_stat_t*
Arena::CreateMaybeMessage< ::bbts::gc_request_evict_stat_t >(Arena* arena) {
  return Arena::CreateMessageInternal< ::bbts::gc_request_evict_stat_t >(arena);
}
template<> PROTOBUF_NOINLINE ::bbts::gc_request_stat_t*
Arena::CreateMaybeMessage< ::bbts::gc_request_stat_t >(Arena* arena) {
  return Arena::CreateMessageInternal< ::bbts::gc_request_stat_t >(arena);
}
template<> PROTOBUF_NOINLINE ::bbts::gpu_device_log_t*
Arena::CreateMaybeMessage< ::bbts::gpu_device_log_t >(Arena* arena) {
  return Arena::CreateMessageInternal< ::bbts::gpu_device_log_t >(arena);
}
template<> PROTOBUF_NOINLINE ::bbts::gpu_profiler_log_t*
Arena::CreateMaybeMessage< ::bbts::gpu_profiler_log_t >(Arena* arena) {
  return Arena::CreateMessageInternal< ::bbts::gpu_profiler_log_t >(arena);
}
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
